---
title: "Workflow"
author: 
  - Leslie CIETERS^[leslie.cieters@agrocampus-ouest.fr]
  - Nemo DIDIER^[nemo.didier@agrocampus-ouest.fr]
  - Sara LARCHER^[sara.larcher@agrocampus-ouest.fr]
date: "2025-01-15"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: flatly
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

------------------------------------------------------------------------

::: {#introduction style="text-align: justify;"}
Les maladies simples sont **monogéniques**, issues de mutations localisées sur les exons, et bien étudiées. Elles déclenchent des phénotypes précis, permettant d'identifier facilement le lien entre un phénotype et le gène impliqué. En revanche, les maladies complexes, **multigéniques**, peuvent impacter d'autres régions moins bien connues que les exons et plusieurs régions à la fois. Il est donc difficile, à partir des phénotypes, de déterminer les gènes impliqués.

L'**objectif** de ce document est de proposer, pour chaque maladie complexe, une liste des gènes impliqués. Pour cela, nous exploitons les maladies simples proches d'une maladie complexe donnée pour identifier des phénotypes communs, permettant de définir une liste de gènes potentiellement responsables de la maladie complexe afin d'orienter la recherche. **Les associations gène-maladie ne sont pas interprétées à ce stade**.

*Cette démarche s'inscrit dans une volonté d'aide à la recherche médicale et ne doit pas être utilisée telle quelle.*
:::

## Démarche

::: {style="test-align: justify"}
Le projet s’articule autour de deux étapes principales :

1.  **Calcul des coordonnées des maladies dans un nombre de dimensions finis** : Il s'agit de projeter des maladies simples et complexes dans un espace commun. Afin de calculer ces coordonnées, nous utilisons plusieurs méthodes dont le calcul préalable d'une matrice de distance selon plusieurs métriques. D'autres méthodes permettent l'obtention directe des coordonnées et ne nécessitent pas une étape préalable

2.  **Définition d’un seuil d’assignation des gènes** : On utilise un seuil global ou spécifique à chaque maladie complexe, au travers de plusieurs méthodes.

À chacune des étapes nous cherchons à comparer plusieurs méthodes pour obtenir la plus adaptée à notre contexte.Par la suite, on utilise des modèles de langage afin d'interpréter les associations gène-maldie obtenues mais cette interprétation n'est pas incluse dans le workflow.
:::

![Démarche mise en place dans le Workflow](images/schema_workflow)

## Packages requis

::: {style="text-align: justify"}
Les packages suivants sont utilisés dans ce workflow
:::

```{r import_packages, message=FALSE, warning=FALSE}

require(tidyverse)
require(FactoMineR)
require(ade4)
require(vegan)
require(reshape)
require(DataExplorer)
require(smacof)
require(Matrix)
require(proxy)
require(pheatmap)
require(ontologyIndex)
require(knitr)

```

# Préparation des données

------------------------------------------------------------------------

Les données initiales sont isssues de deux bases de données différentes :

-   `OMIM` pour les maladies simples

-   `Phecode` pour les maladies complexes

Il s'agit de tableau de Présence/Absence où chaque ligne représente une maladie et chaque colonne un phénotype

|           | Phénotype 1 | Phénotype 2 |
|:---------:|:-----------:|:-----------:|
| Maladie 1 |      0      |      1      |
| Maladie 2 |      1      |      1      |
| Maladie 3 |      1      |      0      |

: **Structure des données**

::: {style="text-align:justify"}
Les phénotypes peuvent différer d'une base à une autre. Afin de comparer maladies simples et complexes, on ne récupère que les phénotypes communs aux deux bases de données. De plus on retire du jeu de données final, toutes les maladies ne présentant pas de variabilité dans les phénotypes observés (c'est-à-dire ne présentant que des absences pour l'ensemble des phénotypes étudiés).
:::

## Prétraitement

```{r pretraitement_data,eval=FALSE}

# Importation des données 
Phe_OMIM <- read.csv('Profils_Base_OMIM.csv')
Phe_Phecode <- read.csv('Profils_Base_Phecodes.csv')

# Passage des noms de maladies en noms de lignes
rownames(Phe_OMIM) <- Phe_OMIM[,1]
rownames(Phe_Phecode) <- Phe_Phecode[,1]
Phe_OMIM <- Phe_OMIM[,-1]
Phe_Phecode <- Phe_Phecode[,-1]

# Intersection des ensembles de phénotypes des deux bases de données
colonnes_communes <- intersect(colnames(Phe_OMIM), colnames(Phe_Phecode))
Phe_OMIM_communes <- Phe_OMIM[, colonnes_communes, drop = FALSE]
Phe_Phecode_communes <- Phe_Phecode[, colonnes_communes, drop = FALSE]

# Fusion des jeux de données 
mc_ms_communes <- rbind(Phe_OMIM_communes, Phe_Phecode_communes)

# Filtre des maladies sans variabilité 
mc_ms_communes_filtre_row <- mc_ms_communes %>%
  filter(rowSums(mc_ms_communes)!=0)
mc_ms_communes_filtre_col_row <- mc_ms_communes_filtre_row %>%
  select(where(~sum(.) != 0))
mc_ms_communes_filtre_col_row <- mc_ms_communes_filtre_row[, colSums(mc_ms_communes_filtre_row) != 0]

phenotype_maladie_s_c <- mc_ms_communes_filtre_col_row
phenotype_maladie_s_c <-  as.data.frame(phenotype_maladie_s_c)

# Sauvegarde du jeu de données prétraité
save(phenotype_maladie_s_c, file="phenotype_maladie_s_c.RData")
```

## Chargement

```{r load_data}

# Chargement du jeu de données sauvegardé 
load('phenotype_maladie_s_c.RData')

# Fichiers HPO pour obtenir le nom des phénotypes 
hpo_url <- "https://raw.githubusercontent.com/obophenotype/human-phenotype-ontology/master/hp.obo"
hpo <- get_ontology(hpo_url, extract_tags = 'everything')

name_ph <- hpo$name
formatted_colnames <- gsub("\\.", ":", colnames(phenotype_maladie_s_c))

# Changement des codes phénotypes par leur nom complet
colnames(phenotype_maladie_s_c) <- name_ph[formatted_colnames]

```

## Structure des données

```{r vizu_data}

# Fonction utilitaire pour calculer le pourcentage de valeurs non-nulles
sparsity_stats <- function(matrix) {
  n_nonzero <- sum(matrix != 0)
  total <- prod(dim(matrix))
  return(list(
    densité = n_nonzero/total * 100,
    nb_nonzero = n_nonzero
  ))
}

## Statistiques descriptives

# Séparation des maladies simples et complexes
maladies_simples <- phenotype_maladie_s_c[1:6102,]
maladies_complexes <- phenotype_maladie_s_c[6103:7064,]

# Calcul des statistiques
stats_total <- sparsity_stats(phenotype_maladie_s_c)
stats_simples <- sparsity_stats(maladies_simples)
stats_complexes <- sparsity_stats(maladies_complexes)

# Affichage des résultats
cat(sprintf("Statistiques de densité de la matrice:\n  - Totale: %.2f%%\n  - Maladies simples: %.2f%%\n  - Maladies complexes: %.2f%%",
            stats_total$densité,
            stats_simples$densité,
            stats_complexes$densité))

```

::: {style="test-align:justify"}
On observe que la matrice initiale est creuse. Cela est à prendre en compte dans la suite de l'analyse.
:::

```{r boxplot_data}
## Distribution des associations par type de maladie
# Calcul du nombre de phénotypes par maladie
phenotypes_par_maladie <- rowSums(phenotype_maladie_s_c != 0)

# Création d'un dataframe pour ggplot
df_dist <- data.frame(
  nb_phenotypes = phenotypes_par_maladie,
  type = c(rep("Simple", 6102), rep("Complexe", 962))
)

# Visualisation avec des boxplots
ggplot(df_dist, aes(x = type, y = nb_phenotypes, fill = type)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribution du nombre de phénotypes par type de maladie",
       x = "Type de maladie",
       y = "Nombre de phénotypes associés")+
  theme(legend.position = 'none')
```

```{r phenotypes_data}
## Analyse des phénotypes les plus fréquents
# Calcul des fréquences des phénotypes
phenotype_freq <- colSums(phenotype_maladie_s_c != 0)
top_n <- 20

# Création d'un dataframe pour les top phénotypes
top_phenotypes <- data.frame(
  phenotype = names(sort(phenotype_freq, decreasing = TRUE)[1:top_n]),
  frequency = sort(phenotype_freq, decreasing = TRUE)[1:top_n]
)

# Visualisation
ggplot(top_phenotypes, aes(x = reorder(phenotype, frequency), y = frequency)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Phénotypes les plus fréquents",
       x = "Phénotype",
       y = "Nombre de maladies associées")
```

# Calcul de matrices de distances

------------------------------------------------------------------------

::: {#intro_distances style="test-align: justify"}
Ici on cherche à caluler des distances binaires, c'est-à-dire des distances sur une matrice binaire avec **1=Présence** et **0=Absence**. <br> On note pour la comparaison de deux maladies :
:::

-   $n_{11} = a$ nombre de phénotypes présents dans les deux maladies
-   $n_{10} = b$ nombre de phénotypes présents uniquement dans la première maladie
-   $n_{01} = c$ nombre de phénotypes présents uniquement dans la deuxième maladie
-   $n_{00} = d$ nombre de phénotypes absents dans les deux maladies

## Calcul des distances {.tabset}

### Jaccard {.unnumbered}

Calcule la similarité en fonction de la proportion d'éléments communs.

$$d_{Jaccard}=\sqrt{1-\frac{a}{a+b+c}}$$

```{r jaccard, eval=FALSE}

index_ASCVD <- which(rownames(phenotype_maladie_s_c) == "ASCVD")
rownames(phenotype_maladie_s_c[6103,])
rownames(phenotype_maladie_s_c[6102,])

dist_or_jaccard <- dist.binary(phenotype_maladie_s_c, method = 1)
dist_or_jaccard <- as.data.frame(as.matrix(dist_or_jaccard))
dist_or_jaccard <- dist_or_jaccard[6103:7064, 1:6102]  # Extraction du sous-ensemble MC-MS
dist_or_jaccard_mx <- as.matrix(dist_or_jaccard)

save(dist_or_jaccard_mx, file="dist_or_jaccard_mx.RData")

```

### Sorensen {.unnumbered}

Similaire à la distance de Jaccard mais avec un facteur multiplicatif pour augmenter la pondération des présences communes.

$$d_{Sorensen}=\sqrt{1-\frac{2a}{2a+b+c}}$$

```{r sorensen, eval=FALSE}

dist_or_sorensen <- dist.binary(phenotype_maladie_s_c, method = 5)
dist_or_sorensen <- as.data.frame(as.matrix(dist_or_sorensen))
dist_or_sorensen <- dist_or_sorensen[6103:7064, 1:6102]
dist_or_sorensen_mx <- as.matrix(dist_or_sorensen)

save(dist_or_sorensen_mx, file="dist_or_sorensen_mx.RData")

```

### Sokal et sneath {.unnumbered}

Variation de la distance de Jaccard qui prend en compte les concordances des absences.

$$d_{Sokal-Sneath}=\sqrt{1-\frac{a}{a+2(b+c)}}$$

```{r sokal-sneath,eval=FALSE}

dist_or_sokal_sneath <- dist.binary(phenotype_maladie_s_c, method = 3) 
dist_or_sokal_sneath <- as.data.frame(as.matrix(dist_or_sokal_sneath))
dist_or_sokal_sneath <- dist_or_sokal_sneath[6103:7064, 1:6102]
dist_or_sokal_sneath_mx <- as.matrix(dist_or_sokal_sneath)

save(dist_or_sokal_sneath_mx, file="dist_or_sokal_sneath_mx.RData")

```

### Ochiai {.unnumbered}

Mesure la similarité en fonction du rapport entre la taille des ensembles et des éléments communs.

$$d_{Ochiai}=\sqrt{1-\frac{a}{\sqrt{(a+b)(a+c)}}}$$

```{r ochiai, eval=FALSE}

dist_or_ochiai <- dist.binary(phenotype_maladie_s_c, method = 7)
dist_or_ochiai <- as.data.frame(as.matrix(dist_or_ochiai))
dist_or_ochiai <- dist_or_ochiai[6103:7064, 1:6102]
dist_or_ochiai_mx <- as.matrix(dist_or_ochiai)

save(dist_or_ochiai_mx, file="dist_or_ochiai_mx.RData")

```

### Cosine {.unnumbered}

Similaire à Ochiai pour des données continues. Compare deux ensembles comme des vecteurs dans un espace multidimensionnel.

$$d_{Cosine} = 1 - \frac{a}{\sqrt{(a + b)(a + c)}}$$

```{r cosine, eval=FALSE}

dist_cosine <- dist(phenotype_maladie_s_c, method = "cosine")
dist_cosine <- as.data.frame(as.matrix(dist_cosine))
dist_cosine <- dist_cosine[6103:7064, 1:6102]
dist_or_cosine_mx <- as.matrix(dist_cosine)

save(dist_or_cosine_mx, file="dist_or_cosine_mx.RData")
```

### Rogers et Tanimoto {.unnumbered}

Mesure la similarité en prenant en compte les présences et les absences.

$$d_{Rogers-Tanimoto}=\sqrt{1-\frac{a+d}{a+2(b+c)+d}}$$

```{r rogers-tanimoto,eval=FALSE}

dist_or_rogers_tanimoto  <- dist.binary(phenotype_maladie_s_c, method = 4)
dist_or_rogers_tanimoto <- as.data.frame(as.matrix(dist_or_rogers_tanimoto))
dist_or_rogers_tanimoto <- dist_or_rogers_tanimoto[6103:7064, 1:6102]
dist_or_rogers_tanimoto_mx <- as.matrix(dist_or_rogers_tanimoto)

save(dist_or_rogers_tanimoto_mx, file="dist_or_rogers_tanimoto_mx.RData")

```

### Hamann {.unnumbered}

Mesure qui prend en compte à la fois la présence et l’absence en équilibrant les deux.

$$d_{Hamann}=\sqrt{1-\frac{a-(b+c)+d}{a+b+c+d}}$$

```{r hamann,eval=FALSE}

dist_or_hamann <- dist.binary(phenotype_maladie_s_c, method = 6) 
dist_or_hamann <- as.data.frame(as.matrix(dist_or_hamann))
dist_or_hamann <- dist_or_hamann[6103:7064, 1:6102]
dist_or_hamann_mx <- as.matrix(dist_or_hamann)

save(dist_or_hamann_mx, file="dist_or_hamann_mx.RData")

```

### SMC {.unnumbered}

Le Simple Matching Coefficient (SMC), ou indice de Sokal et Michener, calcule la proportion de concordances parmi tous les éléments.

$$d_{SMC}=\sqrt{1-\frac{a+d}{a+b+c+d}}$$

```{r smc,eval=FALSE}

dist_or_sokal_michener <- dist.binary(phenotype_maladie_s_c, method = 2)
dist_or_sokal_michener <- as.data.frame(as.matrix(dist_or_sokal_michener))
dist_or_sokal_michener <- dist_or_sokal_michener[6103:7064, 1:6102]
dist_or_sokal_michener_mx <- as.matrix(dist_or_sokal_michener)

save(dist_or_sokal_michener_mx, file="dist_or_sokal_michener_mx.RData")

```

## Comparaison des distances

```{r table_comp, echo=FALSE}

# Créer un tableau avec des données
tableau <- data.frame(
  Méthode = c("Jaccard","Sorensen", "Sokal et Sneath", "Ochiai",  "Cosine", "Rogers et Tanimoto", "Hamann", "SMC" ),
  Pertinence = c("Bien adapté pour des données où l'absence est fréquente et où seules les présences sont d'intérêt.",
                 "Utilisée lorsqu’on souhaite plus de poids pour les éléments présents, ce qui est pertinent dans certains jeux de données.",
                 "Pertinente pour des données binaires où les absences sont aussi importantes que les présences.",
                 "Adaptée aux données binaires où l’on veut une mesure de similarité robuste, même pour les ensembles de taille inégale.",
                 "Très adaptée aux données creuses où les ensembles peuvent être représentés comme des vecteurs binaires.",
                 "Adaptée lorsque les absences sont importantes et qu’on veut différencier les éléments présents et absents.",
                 "Utile pour des données où l’absence et la présence sont toutes deux importantes et où l’équilibre est nécessaire.",
                 "Convient pour des ensembles où la présence et l'absence sont toutes deux significatives."
                 ),
  Avantages = c("Simple à calculer et interpréter. Bien adapté pour les données creuses.",
                "Facile à calculer, adaptée pour les données avec une dominance de présence.",
                "Bien équilibré entre présence et absence.",
                "Bien adaptée aux données binaires déséquilibrées, calcul rapide.",
                "Prend bien en compte la direction des vecteurs, souvent utilisé dans des contextes avec des données creuses.",
                "Permet une comparaison nuancée, plus détaillée que le Jaccard.",
                "Robuste et équilibrée entre présence et absence.",
                "Prend en compte les absences et les présences."
                ),
  Inconvénients = c("Ne prend pas en compte les absences simultanées.", 
                    "Ne prend pas bien en compte les absences, moins efficace pour des données très creuses.",
                    "Plus complexe à interpréter que le Jaccard.",
                    "Moins efficace avec des ensembles ayant de nombreuses absences simultanées.",
                    "Peut ne pas être adaptée aux ensembles avec des distributions très inégales des présences et absences.",
                    "Moins robuste si les absences sont trop fréquentes.", 
                    "Plus difficile à interpréter et peut être moins intuitive dans des jeux de données simples.",
                   "Peut accorder trop de poids aux absences, ce qui n'est pas toujours pertinent."
                   )
)

# Afficher le tableau avec kable pour HTML
kable(tableau, caption = "Comparaison des méthodes de distance", format = "html", table.attr = "class='table table-bordered'")
```

::: {#chargement_distances style="text-align:justify"}
Les calculs de distance étant assez longs, nous avons sauvegardé les matrices dans des objets RData. Le code suivant permet de charger les matrices dans notre environnement
:::

```{r load_distance}
load("dist_or_sokal_sneath_mx.RData")
load("dist_or_hamann_mx.RData")
load("dist_or_rogers_tanimoto_mx.RData")
load("dist_or_sokal_michener_mx.RData")
load("dist_or_cosine_mx.RData")
load("dist_or_jaccard_mx.RData")
load("dist_or_ochiai_mx.RData")
load("dist_or_sorensen_mx.RData")
```

# Transport Optimal (TO)

:::{#intro_to style="text-align:justify"}
Le transport optimal est une méthode **holistique et exhaustive** permettant d'établir des correspondances entre les maladies mendéliennes et complexes. Son principal objectif est de **minimiser une distance globale** entre tous les gènes possibles, tout en considérant un ensemble complet de données.

Le Transport optimal n'est appliqué que sur la matrice de distances de Jaccard dans ce workflow 
:::

## Définition de la fonction de TO

```{r def_to}

sinkhorn_transport <- function(a, b, M, reg, numItermax=1000, stopThr=1e-9) {
  # a, b: distributions marginales
  # M: matrice de coût
  # reg: paramètre de régularisation
  # numItermax: nombre maximum d'itérations
  # stopThr: seuil de convergence
  n <- length(a)
  m <- length(b)
  # Initialisation
  u <- rep(1/n, n)
  v <- rep(1/m, m)
  K <- exp(-M/reg)
  
  # Boucle de Sinkhorn
  for(i in 1:numItermax) {
    u_prev <- u
    # Mise à jour de u et v
    u <- a/(K %*% v)
    v <- b/(t(K) %*% u)
    # Vérification de la convergence
    err <- sum(abs(u - u_prev))
    if(err < stopThr) break
  }
  # Calcul de la matrice de transport
  P <- diag(as.vector(u)) %*% K %*% diag(as.vector(v))
  return(P)
}

```

## Utilisation

```{r to, eval=FALSE}
# Utilisation sur la matrice Jaccard
# Normalisation des vecteurs marginaux
a <- rep(1/nrow(dist_or_jaccard_mx), nrow(dist_or_jaccard_mx))
b <- rep(1/ncol(dist_or_jaccard_mx), ncol(dist_or_jaccard_mx))

# Application de l'algorithme de Sinkhorn
transport_matrix <- sinkhorn_transport(
  a = a,
  b = b,
  M = dist_or_jaccard_mx,
  reg = 0.1  # paramètre de régularisation à ajuster
)

# Calcul de la matrice de distance avec transport optimal
ot_matrix <- dist_or_jaccard_mx * transport_matrix
ot_matrix <- as.matrix(ot_matrix)
ot_matrix <- as.data.frame(ot_matrix)

# ot_matrix_numeric <- ot_matrix %>%
#    mutate(across(everything(), ~ as.numeric(as.character(.))))
dist_ot_jaccard  <- as.data.frame(1 - ot_matrix)
dist_ot_jaccard_mx <- as.matrix(dist_ot_jaccard)
save(dist_ot_jaccard_mx, file="dist_ot_jaccard_mx.RData")


```

Le calcul de la matrice de Transport optimal étant assez long, la matrice a été sauvegardée dans l'objet RData `dist_ot_jaccard_mx.RData`. 

```{r load_to}
load("dist_ot_jaccard_mx.RData")
```


# Obtention des coordonnées

::: {#intro_coord style="text-align:justify"}
Le calcul de la distance étant la seule méthode ne permettant pas l'obtention directe des coordonnées des maladies dans un espace commun, Nous pouvons désormais obtenir ces coordonnées sur un nombre défini de dimensions pour l'ensemble des méthodes. Ici nous choisissons arbitrairement 384 dimensions car il s'agit du nombre de dimensions que l'on peut obtenir avec l'embedding.
:::

## MDS unfolding 

:::{#intro_mds style="text-align:justify"}
Appliquer la MDS unfolding sur une matrice de distance asymétrique permet de représenter dans un espace à faible dimension des relations ou préférences entre deux ensembles distincts (individus et objets) où les interactions ne sont pas symétriques, c'est-à-dire que la distance entre un individu et un objet peut différer selon la direction (ici on s'intéresse au lien de causalité d'un gène pour une maladie).

La MDS unfolding génère alors des coordonnées qui préservent au mieux ces asymétries, tout en fournissant une visualisation claire des relations de causalité dans un espace commun.
:::

### Définition de la fonction pour la MDS

```{r fonction_mds,eval=FALSE}

options(timeout = 6000)      # Augmenter le timeout à 10 minutes
execute_mds_unfolding <- function(distance_matrix) {
  coord_fact_mds <- smacofRect(delta = distance_matrix, 
                               ndim = 384, 
                               type = "ratio", 
                               itmax = 30, 
                               eps = 1e-6, 
                               verbose = TRUE)
  return(coord_fact_mds)
}

```

### Calcul de la MDS

```{r mds,eval=FALSE}

# Calcul de la MDS 
coord_fact_mds_sorensen <- execute_mds_unfolding(dist_or_sorensen_mx)
coord_fact_mds_ochiai <- execute_mds_unfolding(dist_or_ochiai_mx)
coord_fact_mds_jaccard <- execute_mds_unfolding(dist_or_jaccard_mx)
coord_fact_mds_ot_jaccard <- execute_mds_unfolding(dist_ot_jaccard_mx)
coord_fact_mds_sokal_sneath <- execute_mds_unfolding(dist_or_sokal_sneath_mx)
coord_fact_mds_sokal_michener <- execute_mds_unfolding(dist_or_sokal_michener_mx)
coord_fact_mds_rogers_tanimoto <- execute_mds_unfolding(dist_or_rogers_tanimoto_mx)
coord_fact_mds_hamann <- execute_mds_unfolding(dist_or_hamann_mx)
coord_fact_mds_cosine <- execute_mds_unfolding(dist_cosine_mx) 

# Sauvegarder les résultats MDS
save(coord_fact_mds_sokal_sneath, file = "coord_fact_mds_sokal_sneath.RData")
save(coord_fact_mds_sokal_michener, file = "coord_fact_mds_sokal_michener.RData") 
save(coord_fact_mds_rogers_tanimoto, file = "coord_fact_mds_rogers_tanimoto.RData")
save(coord_fact_mds_hamann, file = "coord_fact_mds_hamann.RData")
save(coord_fact_mds_cosine, file = "coord_fact_mds_cosine.RData")
save(coord_fact_mds_sorensen, file="coord_fact_mds_sorensen.RData")
save(coord_fact_mds_ochiai, file="coord_fact_mds_ochiai.RData")
save(coord_fact_mds_jaccard, file="coord_fact_mds_jaccard.RData")
save(coord_fact_mds_ot_jaccard, file="coord_fact_mds_ot_jaccard.RData")


```

```{r load_mds}
load("coord_fact_mds_sorensen.RData")
load("coord_fact_mds_ochiai.RData")
load("coord_fact_mds_jaccard.RData")
load("coord_fact_mds_ot_jaccard.RData")
load("coord_fact_mds_hamann.RData")
load("coord_fact_mds_rogers_tanimoto.RData")
load("coord_fact_mds_sokal_michener.RData")
load("coord_fact_mds_sokal_sneath.RData")
load("coord_fact_mds_cosine.RData")
```

## Embedding

:::{#intro_embedding style="text-align:justify"}
L’**embedding** est une technique permettant de représenter des mots, des phrases ou des entités sous forme de vecteurs dans un espace numérique.Elle repose sur la vectorisation de mots individuels ou de phrases entières :

1.  Chaque mot de la phrase est converti en un vecteur dans un espace vectoriel pré-entraîné.

2.  Pour représenter une phrase ou une entité, comme une maladie, la moyenne des vecteurs des mots individuels est calculée.

Pour générer des embeddings adaptés aux maladies complexes, nous utilisons un **prompt spécifique** qui contextualise les phénotypes de chaque maladie


> *"We are a group of individuals suffering from the same disease, but it manifests itself differently in each of us. Here is a list of the symptoms we may experience: [...]"*

Ce prompt met en avant les variations intra-maladie tout en conservant une structure commune pour faciliter la vectorisation.
:::

### Préparation du fichier pur l'embedding

```{r embedding, message=FALSE, warning=FALSE}

# Chargement fichier HPO 
hpo_url <- "https://raw.githubusercontent.com/obophenotype/human-phenotype-ontology/master/hp.obo"

# Récupération de l'ontologie et des noms exacts de chaque phénotype
hpo <- get_ontology(hpo_url, extract_tags = 'everything')
name_ph <- hpo$name
formatted_colnames <- gsub("\\.", ":", colnames(phenotype_maladie_s_c))
# Remplacement des codes phénotypes par les noms exacts
colnames(phenotype_maladie_s_c) <- name_ph[formatted_colnames]

# transformation au format long
df_long <- melt(as.matrix(phenotype_maladie_s_c))
colnames(df_long) <- c('maladie','phenotype','presence')
liste_phenotype <- df_long %>%
  filter(presence == 1) %>%
  group_by(maladie) %>%
  summarise( liste_phenotype = paste('We are a group of individuals suffering from the same disease, but it manifests itself differently in each of us. Here is a list of the symptoms we may experience',
                                     paste(phenotype,
                                           collapse = ", "),
                                     sep = ' : '),
             .groups = 'drop')
liste_phenotype <- unique(liste_phenotype)[,2]

# Sauvegarde du fichier
write_csv(x = liste_phenotype,file = 'embedding_0hierarchie.csv')

```

### Calcul des coordonnées par embedding 

:::{#calcul_embedding style="text-align:justify"}
Le calcul des coordonnées a été réalisé sur Python avec le modèle **SBERT**. Le résultat de l'embedding a été sauvegardé dans le fichier `embeddings_Pheno_SBERT_sans_hierarchie.csv`
:::

```{r recup_embedding}

coord_fact_embedding <- read.csv("embeddings_Pheno_SBERT_sans_hierarchie.csv")

```

## ACM

:::{#intro_acm style="text-align:justify"}

L'objectif de cette ACM (Analyse des Correspondances Multiples) est de projeter les maladies complexes (MC) dans un espace défini par les maladies simples (MS). Pour ce faire, les maladies complexes sont traitées comme des individus supplémentaires, tandis que l'espace de représentation est construit exclusivement à partir des maladies simples.

:::

```{r acm, eval=FALSE}

# Calcul de l'ACM
dta_acm <- data.frame(lapply(phenotype_maladie_s_c, as.factor))
res.acm<- MCA(dta_acm, ind.sup = c(6103:7064), graph = TRUE, ncp=384)
save(res.acm, file = "res.acm.RData")

# Obtention des coordonnées
col_acm <- res.acm$ind$coord
row_acm <- res.acm$ind.sup$coord
coord_fact_acm <- rbind(col_acm, row_acm)
coord_fact_acm <- as.data.frame(coord_fact_acm)
save(coord_fact_acm, file = "coord_fact_acm.RData")
```

```{r load_acm}

load("res.acm.RData")
load("coord_fact_acm.RData")

```


# Comparaison de l'ensemble des méthodes

:::{#intro_afm style="text-align:justify"}
Afin de comparer l'ensemble de nos méthodes, nous réalisons une Analyse Factorielle Multiple (AFM) sur les coordonnées obtenues par chaque méthodes sur l'ensemble de nos dimensions. Ainsi nous considérons nos dimensions comme des variables et nos méthodes comme des groupes.
:::

## Mise en forme des données pour l'AFM 

```{r data_afm,eval=FALSE}
maladies_acm <- res.acm$ind.sup$coord
maladies_sorensen <- as.data.frame(coord_fact_mds_sorensen$conf.row)
maladies_ochiai <- as.data.frame(coord_fact_mds_ochiai$conf.row)
maladies_jaccard <- as.data.frame(coord_fact_mds_jaccard$conf.row)
maladies_ot_jaccard <- as.data.frame(coord_fact_mds_ot_jaccard$conf.row)
head(coord_fact_embedding)
maladies_embedding <- as.data.frame(coord_fact_embedding[6103:7064, ])
maladies_sokal_sneath <- as.data.frame(coord_fact_mds_sokal_sneath$conf.row)
maladies_sokal_michener <- as.data.frame(coord_fact_mds_sokal_michener$conf.row)
maladies_rogers_tanimoto <- as.data.frame(coord_fact_mds_rogers_tanimoto$conf.row)
maladies_hamann <- as.data.frame(coord_fact_mds_hamann$conf.row)
maladies_cosine <- as.data.frame(coord_fact_mds_cosine$conf.row)

data_pour_afm.toutes.distances <- cbind(maladies_acm, 
                                        maladies_sorensen, 
                                        maladies_ochiai, 
                                        maladies_jaccard, 
                                        maladies_ot_jaccard,
                                        maladies_embedding,  # Données existantes
                                        maladies_sokal_sneath,
                                        maladies_sokal_michener, 
                                        maladies_rogers_tanimoto,
                                        maladies_hamann,
                                        maladies_cosine)
save(data_pour_afm.toutes.distances, file = "data_pour_afm.toutes.distances.RData")

```

## AFM

```{r afm, eval=FALSE}
load("data_pour_afm.toutes.distances.RData")
res.mfa.toutes.distances <- MFA(data_pour_afm.toutes.distances, 
                                group = c(384, 384, 384, 384, 384, 384,  # Groupes existants
                                          384, 384, 384, 384, 384),  # Nouveaux groupes
                                type = c("c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c"), 
                                ncp = 2,             
                                name.group = c("ACM", "Sorensen", "Ochiai", "Jaccard", "Jaccard_OT", "Embedding",
                                               "sokal_sneath", "sokal_michener", "rogers_tanimoto", "Hamann", "Cosine"),graph = FALSE)
save(res.mfa.toutes.distances, file = "res.mfa.toutes.distances.RData")
```

## Représentation graphique 

```{r plot_afm, message=FALSE, warning=FALSE}
load("res.mfa.toutes.distances.RData")
plot(res.mfa.toutes.distances,choix="group",title="Graphe des groupes")
plot(res.mfa.toutes.distances,choix="axes",title="Graphe des axes partiels")
```

# Assignation de gènes 

## Permutations 

### Définnition des fonctions 

```{r fonction_permut}
# Fonctions vectorisées pour chaque type de distance afin d'effectuer plus rapidement les calculs
calc_distances <- function(matrix1, vector1, method = "sorensen") {
  # Calcul du nombre d'éléments communs (intersections)
  a <- matrix1 %*% vector1
  # Nombre total d'éléments dans chaque ligne de la matrice
  nb_elements_ensemble1 <- rowSums(matrix1)
  b = nb_elements_ensemble1 - a
  # Nombre total d'éléments dans le vecteur
  nb_elements_ensemble2 <- sum(vector1)
  c = nb_elements_ensemble2 - a
  # Calcul du nombre d'éléments présents dans aucun des deux ensembles (d)
  d <- ncol(matrix1) - (a + b + c)
  switch(method,
         "jaccard" = {
           sqrt(1-((a) / (a + b + c)))
         },
         "sokal_michener" = {
           sqrt(1-((a + d )/ (a + b + c+ d)))
         },
         "sokal_sneath" = {
           sqrt(1-((a * d) / (sqrt((a + b) + (a + c)+ (d + b) + (d + c)))))
         },
         "rogers_tanimoto" = {
           sqrt(1-((a + d )/ (a + 2*(b + c)+ d)))
         },
         "sorensen" = {
           sqrt(1-((2*a)/ (2*a + b + c)))
         },
         "hamann" = {
           sqrt(1-((a-(b + c) + d)/(a + b + c+ d)))
         },
         "ochiai" = {
           sqrt(1-((a)/(sqrt(a + b)+(a + c))))
         },
         "cosinus" = {
           1-((a)/(sqrt(a + b)+(a + c)))
         }
  )
}

# Fonction de permutation pour une ligne
permut_all <- function(dta, n_perm, line_idx, distance_method = "sorensen") {
  dta <- as.matrix(dta)
  row <- dta[line_idx, ]
  original_rowname <- rownames(dta)[line_idx]
  pmin <- numeric(n_perm)
  other_rows <- matrix(as.numeric(dta[-line_idx, ]), 
                       nrow = nrow(dta) - 1,
                       byrow = FALSE)
  for(i in 1:n_perm) {
    permuted_row <- sample(row, length(row), replace = FALSE)
    distances <- calc_distances(other_rows, permuted_row, method = distance_method)
    pmin[i] <- min(distances)
  }
  
  return(c(rowname = original_rowname, threshold = min(pmin)))
}

# Fonction pour traiter plusieurs lignes
process_multiple_rows <- function(dta, n_perm, start_idx, end_idx, distance_method = "sorensen") {
  n_rows <- end_idx - start_idx + 1
  results <- matrix(nrow = n_rows, ncol = 2)
  for(i in 1:n_rows) {
    curr_idx <- start_idx + i - 1
    results[i, ] <- permut_all(dta, n_perm, curr_idx, distance_method)
  }
  results_df <- as.data.frame(results)
  colnames(results_df) <- c("rowname", "threshold")
  return(results_df)
}

# Fonction pour exécuter toutes les méthodes de distance
run_all_distances <- function(phenotype_matrix, n_perm = 10, start_idx = 6103, end_idx = 7064) {
  distance_methods <- c("sorensen", "ochiai", "jaccard", "sokal_sneath", 
                        "sokal_michener", "rogers_tanimoto", "hamann", "cosinus")
  results <- list()
  for(method in distance_methods) {
    cat("Processing", method, "distance...\n")
    results[[method]] <- process_multiple_rows(
      phenotype_matrix, 
      n_perm = n_perm, 
      start_idx = start_idx, 
      end_idx = end_idx,
      distance_method = method
    )
    results[[method]]$threshold <- as.numeric(results[[method]]$threshold)
  }
  return(results)
}
```

### Application des permutations 

```{r execute_permut}
# Exécuter toutes les distances
results_all <- run_all_distances(phenotype_maladie_s_c)
save(results_all, file="results_all.RData")
```

```{r load_permut}
load ("results_all.RData")
```

### Création des matrices d'assignation 

```{r fonction_matrice_assignation}
# Matrice d'assignation  ----
create_all_association_matrices <- function(results_all) {
  # Liste des matrices de distance à charger
  distance_files <- list(
    sorensen = "dist_or_sorensen_mx.RData",
    ochiai = "dist_or_ochiai_mx.RData",
    jaccard = "dist_or_jaccard_mx.RData",
    sokal_sneath = "dist_or_sokal_sneath_mx.RData",
    sokal_michener = "dist_or_sokal_michener_mx.RData",
    rogers_tanimoto = "dist_or_rogers_tanimoto_mx.RData",
    hamann = "dist_or_hamann_mx.RData",
    cosine = "dist_cosine_mx.RData"
  )
  # Stocker les résultats
  association_matrices <- list()
  # Pour chaque distance
  for(dist_name in names(distance_files)) {
    # Charger la matrice de distance
    load(distance_files[[dist_name]])
    # Obtenir le nom de l'objet chargé
    dist_matrix_name <- gsub("\\.RData$", "", distance_files[[dist_name]])
    dist_matrix <- get(dist_matrix_name)
    # Créer la matrice d'association
    cat("Processing", dist_name, "distance...\n")
    # Conversion en dataframe
    dist_df <- as.data.frame(dist_matrix)
    # Créer une matrice vide
    association_matrix <- matrix(0, nrow = nrow(dist_df), ncol = ncol(dist_df))
    # Pour chaque ligne
    for(i in 1:nrow(dist_df)) {
      # Récupérer le seuil correspondant
      current_threshold <- results_all[[dist_name]]$threshold[i]
      # Comparer les valeurs au seuil
      association_matrix[i,] <- ifelse(dist_df[i,] <= current_threshold, 1, 0)
    }
    # Convertir en dataframe
    association_matrix <- as.data.frame(association_matrix)
    rownames(association_matrix) <- rownames(dist_df)
    colnames(association_matrix) <- colnames(dist_df)
    # Stocker la matrice
    association_matrices[[dist_name]] <- association_matrix
    # Sauvegarder la matrice
    save_name <- paste0("association_matrix_", dist_name, ".RData")
    save(association_matrix, file = save_name)
  }
  return(association_matrices)
}
```

```{r matrice_assignation}

# Créer toutes les matrices d'association
association_matrices <- create_all_association_matrices(results_all)
save(association_matrices, file="association_matrices.RData")

```

