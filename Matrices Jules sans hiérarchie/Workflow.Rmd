---
title: "Workflow"
author: 
  - Leslie CIETERS^[M2 Science des données, Institut Agro Rennes Angers - leslie.cieters@agrocampus-ouest.fr]
  - Nemo DIDIER^[M2 Science des données, Institut Agro Rennes Angers - nemo.didier@agrocampus-ouest.fr]
  - Sara LARCHER^[M2 Science des données, Institut Agro Rennes Angers - sara.larcher@agrocampus-ouest.fr]
output: 
  html_document:
    toc: true
    toc_float: 
      collapsed: false
    number_sections: true
    theme: flatly
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
```

# **Introduction**

------------------------------------------------------------------------

::: {#introduction style="text-align: justify;"}
Les maladies simples ou mendéliennes sont **monogéniques**, c'est-à-dire qu'elles sont dues à des anomalies génétiques qui ne concernent qu’un seul gène. Ces anomalies sont situées sur les exons (parties codantes de l'ADN) et souvent très bien étudiées. Elles déclenchent des phénotypes précis, permettant d'identifier facilement le lien entre un phénotype et le gène impliqué. En revanche, les maladies complexes, **multigéniques**, sont liées à plusieurs gènes, chacun d’entre eux n’est ni indispensable, ni suffisant, pour causer à lui seul la maladie. Il s'agit de **gènes de susceptibilité** (Libioulle C., Bours V. Rev Med Liege 2012, 67(5-6),220-225.). Les anomalies peuvent impacter d'autres régions moins bien connues que les exons et plusieurs régions à la fois. Il est donc difficile, à partir des phénotypes, de déterminer les gènes impliqués.

L'**objectif** de ce document est de proposer une démarche complète permettant, pour chaque maladie complexe, d'obtenir une liste de gènes de susceptibilité. Pour cela, nous exploitons les phénotypes des maladies simples et complexes afin d'identifier, pour une maladie complexe, des maladies simples proches, permettant de définir une liste de gènes potentiellement causes de la maladie complexe.

*Cette démarche s'inscrit dans une volonté d'aide à la recherche médicale et ne doit pas être utilisée telle quelle.*
:::

## Hypothèses

:::{#hypotheses style="text-align:justify"}
Nous partons des hypothèses suivantes :

-   Il est possible de comprendre les maladies complexes en les rapprochant de maladies simples similaires.

-   Nous négligeons l’épistasie (interaction complexe entre l'expression de plusieurs gènes).

-   Les phénotypes ne sont pas hiérarchisés. Nous partons du postulat que seul le niveau phénotypique le plus fin est présent dans le jeu de données.
:::

## Démarche

::: {#demarche style="test-align: justify"}
Le projet s’articule autour de trois étapes principales :

1.  **Calcul des coordonnées des maladies dans un nombre de dimensions finis** : Il s'agit de projeter des maladies simples et complexes dans un espace commun. Nous avons fait le choix d'utiliser uniquement des méthodes basées sur ce principe. Afin de calculer ces coordonnées, nous utilisons donc plusieurs méthodes dont le calcul préalable d'une matrice de distance selon plusieurs métriques. D'autres méthodes permettent l'obtention directe des coordonnées et ne nécessitent pas une étape préalable.

2.  **Définition d’un seuil d’assignation des gènes** : On utilise un seuil global ou spécifique à chaque maladie complexe, au travers de plusieurs méthodes, afin de définir notre croyance en une association et donc de conserver une liste d'associations gène-maladie que l'on pense fortement corrélées à la maladie étudiée.

3. **Interprétation des associations gène-maladie** : On définie un score de pertinence de l'association gène-maladie par le biais d'un large modèle de langage (LLM).

À chacune des étapes nous cherchons à comparer plusieurs méthodes pour obtenir la plus adaptée à notre contexte.
:::

![Schéma général de la démarche](images/schema_workflow)

## Packages requis

::: {#packages style="text-align: justify"}
Les packages suivants sont utilisés dans ce workflow. Il est également nécessaire d'installer **LLama** pour la partie interprétation des associations qui fait appel à Llama3.
:::

```{r import_packages, message=FALSE, warning=FALSE}

require(ade4)
require(cluster)
require(DataExplorer)
require(factoextra)
require(FactoMineR)
require(knitr)
require(Matrix)
require(ontologyIndex)
require(pheatmap)
require(proxy)
require(reshape)
require(smacof)
require(tidyverse)
require(vegan)

```

# **Préparation des données**

------------------------------------------------------------------------

Les données utilisées sont isssues de deux bases de données différentes :

-   `OMIM` pour les maladies simples

-   `Phecode` pour les maladies complexes

Il s'agit de tableau de Présence/Absence où chaque ligne représente une maladie et chaque colonne un phénotype. 

|           | Phénotype 1 | Phénotype 2 |
|:---------:|:-----------:|:-----------:|
| Maladie 1 |      0      |      1      |
| Maladie 2 |      1      |      1      |
| Maladie 3 |      1      |      0      |

: **Structure des données**

::: {#structure_data style="text-align:justify"}
Il existe une variabilité intra-maladie pour les phénotypes. Un `1` dans la matrice de présence-absence ne signifie pas que ce phénotype est observé pour l'ensemble des patients atteint de cette maladie. De même un `0` ne signifie pas forcément que le phénotype n'est pas observé pour cette maladie mais qu'il n'est pas observé dans la population étudiée.

La liste des phénotypes peut différer d'une base à une autre. Afin de comparer maladies simples et complexes, nous ne récupérons que les phénotypes communs aux deux bases de données. De plus nous retirons du jeu de données final toutes les maladies ne présentant pas de variabilité dans les phénotypes observés (c'est-à-dire ne présentant que des absences pour l'ensemble des phénotypes étudiés).
:::

## Prétraitement

```{r pretraitement_data,eval=FALSE}

# Importation des données 
Phe_OMIM <- read.csv('Profils_Base_OMIM.csv')
Phe_Phecode <- read.csv('Profils_Base_Phecodes.csv')

# Passage des noms de maladies en noms de lignes
rownames(Phe_OMIM) <- Phe_OMIM[,1]
rownames(Phe_Phecode) <- Phe_Phecode[,1]
Phe_OMIM <- Phe_OMIM[,-1]
Phe_Phecode <- Phe_Phecode[,-1]

# Intersection des ensembles de phénotypes des deux bases de données
colonnes_communes <- intersect(colnames(Phe_OMIM), colnames(Phe_Phecode))
Phe_OMIM_communes <- Phe_OMIM[, colonnes_communes, drop = FALSE]
Phe_Phecode_communes <- Phe_Phecode[, colonnes_communes, drop = FALSE]

# Fusion des jeux de données 
mc_ms_communes <- rbind(Phe_OMIM_communes, Phe_Phecode_communes)

# Filtre des maladies sans variabilité 
mc_ms_communes_filtre_row <- mc_ms_communes %>%
  filter(rowSums(mc_ms_communes)!=0)
mc_ms_communes_filtre_col_row <- mc_ms_communes_filtre_row %>%
  select(where(~sum(.) != 0))
mc_ms_communes_filtre_col_row <- mc_ms_communes_filtre_row[, colSums(mc_ms_communes_filtre_row) != 0]

phenotype_maladie_s_c <- mc_ms_communes_filtre_col_row
phenotype_maladie_s_c <-  as.data.frame(phenotype_maladie_s_c)

# Sauvegarde du jeu de données prétraité
save(phenotype_maladie_s_c, file="phenotype_maladie_s_c.RData")
```

## Chargement

::: {#chargement_data style="text-align:justify"}
Pour plus de facilité d'interprétation et de visualisation, les codes phénotypes initialement utilisés dans le jeu de données sont remplacés par leurs noms exacts.
:::

```{r load_data}

# Chargement du jeu de données sauvegardé 
load('phenotype_maladie_s_c.RData')

# Fichiers HPO pour obtenir le nom des phénotypes 
hpo_url <- "https://raw.githubusercontent.com/obophenotype/human-phenotype-ontology/master/hp.obo"
hpo <- get_ontology(hpo_url, extract_tags = 'everything')

name_ph <- hpo$name
formatted_colnames <- gsub("\\.", ":", colnames(phenotype_maladie_s_c))

# Changement des codes phénotypes par leurs noms complets
colnames(phenotype_maladie_s_c) <- name_ph[formatted_colnames]

```

## Structure

::: {#structure_data style="text-align:justify"}
Avant d'appliquer nos méthodes, nous nous intéressons à la structure des données
:::

```{r vizu_data}

# Fonction utilitaire pour calculer le pourcentage de valeurs non-nulles
sparsity_stats <- function(matrix) {
  n_nonzero <- sum(matrix != 0)
  total <- prod(dim(matrix))
  return(list(
    densité = n_nonzero/total * 100,
    nb_nonzero = n_nonzero
  ))
}

## Statistiques descriptives

# Séparation des maladies simples et complexes
maladies_simples <- phenotype_maladie_s_c[1:6102,]
maladies_complexes <- phenotype_maladie_s_c[6103:7064,]

# Calcul des statistiques
stats_total <- sparsity_stats(phenotype_maladie_s_c)
stats_simples <- sparsity_stats(maladies_simples)
stats_complexes <- sparsity_stats(maladies_complexes)

# Affichage des résultats
cat(sprintf("Statistiques de densité de la matrice:\n  - Totale: %.2f%%\n  - Maladies simples: %.2f%%\n  - Maladies complexes: %.2f%%",
            stats_total$densité,
            stats_simples$densité,
            stats_complexes$densité))

```

::: {#matrice creuse style="test-align:justify"}
On observe que la matrice initiale est creuse. Cela est à prendre en compte dans la suite de l'analyse.
:::

```{r boxplot_data}
## Distribution des associations par type de maladie
# Calcul du nombre de phénotypes par maladie
phenotypes_par_maladie <- rowSums(phenotype_maladie_s_c != 0)

# Création d'un dataframe pour ggplot
df_dist <- data.frame(
  nb_phenotypes = phenotypes_par_maladie,
  type = c(rep("Simple", 6102), rep("Complexe", 962))
)

# Visualisation avec des boxplots
ggplot(df_dist, aes(x = type, y = nb_phenotypes, fill = type)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribution du nombre de phénotypes par type de maladie",
       x = "Type de maladie",
       y = "Nombre de phénotypes associés")+
  theme(legend.position = 'none')
```

```{r phenotypes_data}
## Analyse des phénotypes les plus fréquents
# Calcul des fréquences des phénotypes
phenotype_freq <- colSums(phenotype_maladie_s_c != 0)
top_n <- 20

# Création d'un dataframe pour les top phénotypes
top_phenotypes <- data.frame(
  phenotype = names(sort(phenotype_freq, decreasing = TRUE)[1:top_n]),
  frequency = sort(phenotype_freq, decreasing = TRUE)[1:top_n]
)

# Visualisation
ggplot(top_phenotypes, aes(x = reorder(phenotype, frequency), y = frequency)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Phénotypes les plus fréquents",
       x = "Phénotype",
       y = "Nombre de maladies associées")
```

# **Calcul des matrices de distances**

------------------------------------------------------------------------

::: {#intro_distances style="test-align: justify"}
Ici on cherche à calculer des distances binaires, c'est-à-dire des distances sur une matrice binaire avec **1=Présence** et **0=Absence**. <br> On note pour la comparaison de deux maladies :
:::

-   $n_{11} = a$ nombre de phénotypes présents dans les deux maladies
-   $n_{10} = b$ nombre de phénotypes présents uniquement dans la première maladie
-   $n_{01} = c$ nombre de phénotypes présents uniquement dans la deuxième maladie
-   $n_{00} = d$ nombre de phénotypes absents dans les deux maladies

## Calculs {.tabset}

### Jaccard {.unnumbered}

Calcule la similarité en fonction de la proportion d'éléments communs.

$$d_{Jaccard}=\sqrt{1-\frac{a}{a+b+c}}$$

```{r jaccard, eval=FALSE}

index_ASCVD <- which(rownames(phenotype_maladie_s_c) == "ASCVD")
rownames(phenotype_maladie_s_c[6103,])
rownames(phenotype_maladie_s_c[6102,])

dist_or_jaccard <- dist.binary(phenotype_maladie_s_c, method = 1)
dist_or_jaccard <- as.data.frame(as.matrix(dist_or_jaccard))
dist_or_jaccard <- dist_or_jaccard[6103:7064, 1:6102]  # Extraction du sous-ensemble MC-MS
dist_or_jaccard_mx <- as.matrix(dist_or_jaccard)

save(dist_or_jaccard_mx, file="dist_or_jaccard_mx.RData")

```

### Sorensen {.unnumbered}

Similaire à la distance de Jaccard mais avec un facteur multiplicatif pour augmenter la pondération des présences communes.

$$d_{Sorensen}=\sqrt{1-\frac{2a}{2a+b+c}}$$

```{r sorensen, eval=FALSE}

dist_or_sorensen <- dist.binary(phenotype_maladie_s_c, method = 5)
dist_or_sorensen <- as.data.frame(as.matrix(dist_or_sorensen))
dist_or_sorensen <- dist_or_sorensen[6103:7064, 1:6102]
dist_or_sorensen_mx <- as.matrix(dist_or_sorensen)

save(dist_or_sorensen_mx, file="dist_or_sorensen_mx.RData")

```

### Sokal et sneath {.unnumbered}

Variation de la distance de Jaccard qui prend en compte les concordances des absences, c'est-à-dire les différences entre deux maladies (b et c).

$$d_{Sokal-Sneath}=\sqrt{1-\frac{a}{a+2(b+c)}}$$

```{r sokal-sneath,eval=FALSE}

dist_or_sokal_sneath <- dist.binary(phenotype_maladie_s_c, method = 3) 
dist_or_sokal_sneath <- as.data.frame(as.matrix(dist_or_sokal_sneath))
dist_or_sokal_sneath <- dist_or_sokal_sneath[6103:7064, 1:6102]
dist_or_sokal_sneath_mx <- as.matrix(dist_or_sokal_sneath)

save(dist_or_sokal_sneath_mx, file="dist_or_sokal_sneath_mx.RData")

```

### Ochiai {.unnumbered}

Mesure la similarité en fonction du rapport entre la taille des ensembles et des éléments communs.

$$d_{Ochiai}=\sqrt{1-\frac{a}{\sqrt{(a+b)(a+c)}}}$$

```{r ochiai, eval=FALSE}

dist_or_ochiai <- dist.binary(phenotype_maladie_s_c, method = 7)
dist_or_ochiai <- as.data.frame(as.matrix(dist_or_ochiai))
dist_or_ochiai <- dist_or_ochiai[6103:7064, 1:6102]
dist_or_ochiai_mx <- as.matrix(dist_or_ochiai)

save(dist_or_ochiai_mx, file="dist_or_ochiai_mx.RData")

```

### Cosine {.unnumbered}

Similaire à Ochiai pour des données continues. Compare deux ensembles comme des vecteurs dans un espace multidimensionnel.

$$d_{Cosine} = 1 - \frac{a}{\sqrt{(a + b)(a + c)}}$$

```{r cosine, eval=FALSE}

dist_cosine <- dist(phenotype_maladie_s_c, method = "cosine")
dist_cosine <- as.data.frame(as.matrix(dist_cosine))
dist_cosine <- dist_cosine[6103:7064, 1:6102]
dist_or_cosine_mx <- as.matrix(dist_cosine)

save(dist_or_cosine_mx, file="dist_or_cosine_mx.RData")
```

### Rogers et Tanimoto {.unnumbered}

Mesure la similarité en prenant en compte les présences et les absences.

$$d_{Rogers-Tanimoto}=\sqrt{1-\frac{a+d}{a+2(b+c)+d}}$$

```{r rogers-tanimoto,eval=FALSE}

dist_or_rogers_tanimoto  <- dist.binary(phenotype_maladie_s_c, method = 4)
dist_or_rogers_tanimoto <- as.data.frame(as.matrix(dist_or_rogers_tanimoto))
dist_or_rogers_tanimoto <- dist_or_rogers_tanimoto[6103:7064, 1:6102]
dist_or_rogers_tanimoto_mx <- as.matrix(dist_or_rogers_tanimoto)

save(dist_or_rogers_tanimoto_mx, file="dist_or_rogers_tanimoto_mx.RData")

```

### Hamann {.unnumbered}

Mesure qui prend en compte à la fois la présence et l’absence en équilibrant les deux.

$$d_{Hamann}=\sqrt{1-\frac{a-(b+c)+d}{a+b+c+d}}$$

```{r hamann,eval=FALSE}

dist_or_hamann <- dist.binary(phenotype_maladie_s_c, method = 6) 
dist_or_hamann <- as.data.frame(as.matrix(dist_or_hamann))
dist_or_hamann <- dist_or_hamann[6103:7064, 1:6102]
dist_or_hamann_mx <- as.matrix(dist_or_hamann)

save(dist_or_hamann_mx, file="dist_or_hamann_mx.RData")

```

### SMC {.unnumbered}

Le Simple Matching Coefficient (SMC), ou indice de Sokal et Michener, calcule la proportion de concordances parmi tous les éléments.

$$d_{SMC}=\sqrt{1-\frac{a+d}{a+b+c+d}}$$

```{r smc,eval=FALSE}

dist_or_sokal_michener <- dist.binary(phenotype_maladie_s_c, method = 2)
dist_or_sokal_michener <- as.data.frame(as.matrix(dist_or_sokal_michener))
dist_or_sokal_michener <- dist_or_sokal_michener[6103:7064, 1:6102]
dist_or_sokal_michener_mx <- as.matrix(dist_or_sokal_michener)

save(dist_or_sokal_michener_mx, file="dist_or_sokal_michener_mx.RData")

```

## Comparaison

```{r table_comp, echo=FALSE}

# Créer un tableau avec des données
tableau <- data.frame(
  Méthode = c("Jaccard","Sorensen", "Sokal et Sneath", "Ochiai",  "Cosine", "Rogers et Tanimoto", "Hamann", "SMC" ),
  Pertinence = c("Bien adapté pour des données où l'absence est fréquente et où seules les présences sont d'intérêt.",
                 "Utilisée lorsqu’on souhaite plus de poids pour les éléments présents, ce qui est pertinent dans certains jeux de données.",
                 "Pertinente pour des données binaires où les absences sont aussi importantes que les présences.",
                 "Adaptée aux données binaires où l’on veut une mesure de similarité robuste, même pour les ensembles de taille inégale.",
                 "Très adaptée aux données creuses où les ensembles peuvent être représentés comme des vecteurs binaires.",
                 "Adaptée lorsque les absences sont importantes et qu’on veut différencier les éléments présents et absents.",
                 "Utile pour des données où l’absence et la présence sont toutes deux importantes et où l’équilibre est nécessaire.",
                 "Convient pour des ensembles où la présence et l'absence sont toutes deux significatives."
                 ),
  Avantages = c("Simple à calculer et interpréter. Bien adapté pour les données creuses.",
                "Facile à calculer, adaptée pour les données avec une dominance de présence.",
                "Bien équilibré entre présence et absence.",
                "Bien adaptée aux données binaires déséquilibrées, calcul rapide.",
                "Prend bien en compte la direction des vecteurs, souvent utilisé dans des contextes avec des données creuses.",
                "Permet une comparaison nuancée, plus détaillée que la distance de Jaccard.",
                "Robuste et équilibrée entre présence et absence.",
                "Prend en compte les absences et les présences."
                ),
  Inconvénients = c("Ne prend pas en compte les absences simultanées.", 
                    "Ne prend pas bien en compte les absences, moins efficace pour des données très creuses.",
                    "Plus complexe à interpréter que le Jaccard.",
                    "Moins efficace avec des ensembles ayant de nombreuses absences simultanées.",
                    "Peut ne pas être adaptée aux ensembles avec des distributions très inégales des présences et absences.",
                    "Moins robuste si les absences sont trop fréquentes.", 
                    "Plus difficile à interpréter et peut être moins intuitive dans des jeux de données simples.",
                   "Peut accorder trop de poids aux absences, ce qui n'est pas toujours pertinent."
                   )
)

# Afficher le tableau avec kable pour HTML
kable(tableau, caption = "Comparaison des méthodes de distance", format = "html", table.attr = "class='table table-bordered'")
```

::: {#chargement_distances style="text-align:justify"}
Les calculs de distance étant assez longs, nous avons sauvegardé les matrices dans des objets RData. Le code suivant permet de charger les matrices dans notre environnement
:::

```{r load_distance}
load("dist_or_sokal_sneath_mx.RData")
load("dist_or_hamann_mx.RData")
load("dist_or_rogers_tanimoto_mx.RData")
load("dist_or_sokal_michener_mx.RData")
load("dist_or_cosine_mx.RData")
load("dist_or_jaccard_mx.RData")
load("dist_or_ochiai_mx.RData")
load("dist_or_sorensen_mx.RData")
```

# **Transport Optimal (TO)**

:::{#intro_to style="text-align:justify"}
Le transport optimal est une méthode **holistique et exhaustive** permettant d'établir des correspondances entre les maladies mendéliennes et complexes. Son principal objectif est de **minimiser une distance globale** entre tous les gènes possibles, tout en considérant un ensemble complet de données.

Le Transport optimal n'est appliqué que sur la matrice de distances de Jaccard dans ce workflow 
:::

## Définition de la fonction de TO

```{r def_to}

sinkhorn_transport <- function(a, b, M, reg, numItermax=1000, stopThr=1e-9) {
  # a, b: distributions marginales
  # M: matrice de coût
  # reg: paramètre de régularisation
  # numItermax: nombre maximum d'itérations
  # stopThr: seuil de convergence
  n <- length(a)
  m <- length(b)
  # Initialisation
  u <- rep(1/n, n)
  v <- rep(1/m, m)
  K <- exp(-M/reg)
  
  # Boucle de Sinkhorn
  for(i in 1:numItermax) {
    u_prev <- u
    # Mise à jour de u et v
    u <- a/(K %*% v)
    v <- b/(t(K) %*% u)
    # Vérification de la convergence
    err <- sum(abs(u - u_prev))
    if(err < stopThr) break
  }
  # Calcul de la matrice de transport
  P <- diag(as.vector(u)) %*% K %*% diag(as.vector(v))
  return(P)
}

```

## Utilisation

```{r to, eval=FALSE}
# Utilisation sur la matrice Jaccard
# Normalisation des vecteurs marginaux
a <- rep(1/nrow(dist_or_jaccard_mx), nrow(dist_or_jaccard_mx))
b <- rep(1/ncol(dist_or_jaccard_mx), ncol(dist_or_jaccard_mx))

# Application de l'algorithme de Sinkhorn
transport_matrix <- sinkhorn_transport(
  a = a,
  b = b,
  M = dist_or_jaccard_mx,
  reg = 0.1  # paramètre de régularisation à ajuster
)

# Calcul de la matrice de distance avec transport optimal
ot_matrix <- dist_or_jaccard_mx * transport_matrix
ot_matrix <- as.matrix(ot_matrix)
ot_matrix <- as.data.frame(ot_matrix)

# ot_matrix_numeric <- ot_matrix %>%
#    mutate(across(everything(), ~ as.numeric(as.character(.))))
dist_ot_jaccard  <- as.data.frame(1 - ot_matrix)
dist_ot_jaccard_mx <- as.matrix(dist_ot_jaccard)
save(dist_ot_jaccard_mx, file="dist_ot_jaccard_mx.RData")


```

Le calcul de la matrice de Transport optimal étant assez long, la matrice a été sauvegardée dans l'objet RData `dist_ot_jaccard_mx.RData`. 

```{r load_to}
load("dist_ot_jaccard_mx.RData")
```


# **Obtention des coordonnées**

::: {#intro_coord style="text-align:justify"}
Les autres méthodes de projection des maladies dans un même espace permettent l'obtrention de coordonnées factorielles. Afin de comparer l'ensemble de nos méthodes, y compris les calculs classiques des distances, nous voulons obtenir des coordonnées factorielles pour l'ensemble des méthodes sur un nombre de dimensions équivalents pour chacune. Ici nous choisissons arbitrairement **384 dimensions** car il s'agit du nombre de dimensions que l'on peut obtenir avec l'embedding (facteur limitant).
:::

## MDS unfolding 

:::{#intro_mds style="text-align:justify"}
Appliquer la MDS unfolding sur une matrice de distance asymétrique permet de représenter dans un espace à faible dimension des relations ou préférences entre deux ensembles distincts (individus et objets) où les interactions ne sont pas symétriques, c'est-à-dire que la distance entre un individu et un objet peut différer selon la direction (ici on s'intéresse au lien de causalité d'un gène pour une maladie).

La MDS unfolding génère alors des coordonnées qui préservent au mieux ces asymétries, tout en fournissant une visualisation claire des relations de causalité dans un espace commun.
:::

### Définition de la fonction pour la MDS

```{r fonction_mds,eval=FALSE}

options(timeout = 6000)      # Augmenter le timeout à 10 minutes
execute_mds_unfolding <- function(distance_matrix) {
  coord_fact_mds <- smacofRect(delta = distance_matrix, 
                               ndim = 384, 
                               type = "ratio", 
                               itmax = 30, 
                               eps = 1e-6, 
                               verbose = TRUE)
  return(coord_fact_mds)
}

```

### Calcul de la MDS

```{r mds,eval=FALSE}

# Calcul de la MDS 
coord_fact_mds_sorensen <- execute_mds_unfolding(dist_or_sorensen_mx)
coord_fact_mds_ochiai <- execute_mds_unfolding(dist_or_ochiai_mx)
coord_fact_mds_jaccard <- execute_mds_unfolding(dist_or_jaccard_mx)
coord_fact_mds_ot_jaccard <- execute_mds_unfolding(dist_ot_jaccard_mx)
coord_fact_mds_sokal_sneath <- execute_mds_unfolding(dist_or_sokal_sneath_mx)
coord_fact_mds_sokal_michener <- execute_mds_unfolding(dist_or_sokal_michener_mx)
coord_fact_mds_rogers_tanimoto <- execute_mds_unfolding(dist_or_rogers_tanimoto_mx)
coord_fact_mds_hamann <- execute_mds_unfolding(dist_or_hamann_mx)
coord_fact_mds_cosine <- execute_mds_unfolding(dist_cosine_mx) 

# Sauvegarder les résultats MDS
save(coord_fact_mds_sokal_sneath, file = "coord_fact_mds_sokal_sneath.RData")
save(coord_fact_mds_sokal_michener, file = "coord_fact_mds_sokal_michener.RData") 
save(coord_fact_mds_rogers_tanimoto, file = "coord_fact_mds_rogers_tanimoto.RData")
save(coord_fact_mds_hamann, file = "coord_fact_mds_hamann.RData")
save(coord_fact_mds_cosine, file = "coord_fact_mds_cosine.RData")
save(coord_fact_mds_sorensen, file="coord_fact_mds_sorensen.RData")
save(coord_fact_mds_ochiai, file="coord_fact_mds_ochiai.RData")
save(coord_fact_mds_jaccard, file="coord_fact_mds_jaccard.RData")
save(coord_fact_mds_ot_jaccard, file="coord_fact_mds_ot_jaccard.RData")


```

```{r load_mds}
load("coord_fact_mds_sorensen.RData")
load("coord_fact_mds_ochiai.RData")
load("coord_fact_mds_jaccard.RData")
load("coord_fact_mds_ot_jaccard.RData")
load("coord_fact_mds_hamann.RData")
load("coord_fact_mds_rogers_tanimoto.RData")
load("coord_fact_mds_sokal_michener.RData")
load("coord_fact_mds_sokal_sneath.RData")
load("coord_fact_mds_cosine.RData")
```

## Embedding

:::{#intro_embedding style="text-align:justify"}
L’**embedding** est une technique permettant de représenter des mots, des phrases ou des entités sous forme de vecteurs dans un espace numérique.Elle repose sur la vectorisation de mots individuels ou de phrases entières :

1.  Chaque mot de la phrase est converti en un vecteur dans un espace vectoriel pré-entraîné.

2.  Pour représenter une phrase ou une entité, comme une maladie, la moyenne des vecteurs des mots individuels est calculée.

Pour générer des embeddings adaptés aux maladies complexes, nous utilisons un **prompt spécifique** qui contextualise les phénotypes de chaque maladie


> *"We are a group of individuals suffering from the same disease, but it manifests itself differently in each of us. Here is a list of the symptoms we may experience: [...]"*

Ce prompt met en avant les variations intra-maladie tout en conservant une structure commune pour faciliter la vectorisation.
:::

### Préparation du fichier pur l'embedding

```{r embedding, message=FALSE, warning=FALSE}

# Chargement fichier HPO 
hpo_url <- "https://raw.githubusercontent.com/obophenotype/human-phenotype-ontology/master/hp.obo"

# Récupération de l'ontologie et des noms exacts de chaque phénotype
hpo <- get_ontology(hpo_url, extract_tags = 'everything')
name_ph <- hpo$name
formatted_colnames <- gsub("\\.", ":", colnames(phenotype_maladie_s_c))
# Remplacement des codes phénotypes par les noms exacts
colnames(phenotype_maladie_s_c) <- name_ph[formatted_colnames]

# transformation au format long
df_long <- melt(as.matrix(phenotype_maladie_s_c))
colnames(df_long) <- c('maladie','phenotype','presence')
liste_phenotype <- df_long %>%
  filter(presence == 1) %>%
  group_by(maladie) %>%
  summarise( liste_phenotype = paste('We are a group of individuals suffering from the same disease, but it manifests itself differently in each of us. Here is a list of the symptoms we may experience',
                                     paste(phenotype,
                                           collapse = ", "),
                                     sep = ' : '),
             .groups = 'drop')
liste_phenotype <- unique(liste_phenotype)[,2]

# Sauvegarde du fichier
write_csv(x = liste_phenotype,file = 'embedding_0hierarchie.csv')

```

### Calcul des coordonnées par embedding 

:::{#calcul_embedding style="text-align:justify"}
Le calcul des coordonnées a été réalisé sur Python avec le modèle **SBERT**. Le résultat de l'embedding a été sauvegardé dans le fichier `embeddings_Pheno_SBERT_sans_hierarchie.csv`
:::

```{r recup_embedding}

coord_fact_embedding <- read.csv("embeddings_Pheno_SBERT_sans_hierarchie.csv")

```

## ACM

:::{#intro_acm style="text-align:justify"}

L'objectif de cette ACM (Analyse des Correspondances Multiples) est de projeter les maladies complexes (MC) dans un espace défini par les maladies simples (MS). Pour ce faire, les maladies complexes sont traitées comme des individus supplémentaires, tandis que l'espace de représentation est construit exclusivement à partir des maladies simples.

:::

```{r acm, eval=FALSE}

# Calcul de l'ACM
dta_acm <- data.frame(lapply(phenotype_maladie_s_c, as.factor))
res.acm<- MCA(dta_acm, ind.sup = c(6103:7064), graph = TRUE, ncp=384)
save(res.acm, file = "res.acm.RData")

# Obtention des coordonnées
col_acm <- res.acm$ind$coord
row_acm <- res.acm$ind.sup$coord
coord_fact_acm <- rbind(col_acm, row_acm)
coord_fact_acm <- as.data.frame(coord_fact_acm)
save(coord_fact_acm, file = "coord_fact_acm.RData")
```

```{r load_acm}

load("res.acm.RData")
load("coord_fact_acm.RData")

```


# **Comparaison de l'ensemble des méthodes**

:::{#intro_afm style="text-align:justify"}
Afin de comparer l'ensemble de nos méthodes, nous réalisons une Analyse Factorielle Multiple (AFM) sur les coordonnées obtenues par chaque méthodes sur l'ensemble de nos dimensions. Ainsi nous considérons nos dimensions comme des variables et nos méthodes comme des groupes.
:::

## Mise en forme des données pour l'AFM 

```{r data_afm,eval=FALSE}
maladies_acm <- res.acm$ind.sup$coord
maladies_sorensen <- as.data.frame(coord_fact_mds_sorensen$conf.row)
maladies_ochiai <- as.data.frame(coord_fact_mds_ochiai$conf.row)
maladies_jaccard <- as.data.frame(coord_fact_mds_jaccard$conf.row)
maladies_ot_jaccard <- as.data.frame(coord_fact_mds_ot_jaccard$conf.row)
head(coord_fact_embedding)
maladies_embedding <- as.data.frame(coord_fact_embedding[6103:7064, ])
maladies_sokal_sneath <- as.data.frame(coord_fact_mds_sokal_sneath$conf.row)
maladies_sokal_michener <- as.data.frame(coord_fact_mds_sokal_michener$conf.row)
maladies_rogers_tanimoto <- as.data.frame(coord_fact_mds_rogers_tanimoto$conf.row)
maladies_hamann <- as.data.frame(coord_fact_mds_hamann$conf.row)
maladies_cosine <- as.data.frame(coord_fact_mds_cosine$conf.row)

data_pour_afm.toutes.distances <- cbind(maladies_acm, 
                                        maladies_sorensen, 
                                        maladies_ochiai, 
                                        maladies_jaccard, 
                                        maladies_ot_jaccard,
                                        maladies_embedding,  # Données existantes
                                        maladies_sokal_sneath,
                                        maladies_sokal_michener, 
                                        maladies_rogers_tanimoto,
                                        maladies_hamann,
                                        maladies_cosine)
save(data_pour_afm.toutes.distances, file = "data_pour_afm.toutes.distances.RData")

```

## AFM

```{r afm, eval=FALSE}
load("data_pour_afm.toutes.distances.RData")
res.mfa.toutes.distances <- MFA(data_pour_afm.toutes.distances, 
                                group = c(384, 384, 384, 384, 384, 384,  # Groupes existants
                                          384, 384, 384, 384, 384),  # Nouveaux groupes
                                type = c("c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c"), 
                                ncp = 2,             
                                name.group = c("ACM", "Sorensen", "Ochiai", "Jaccard", "Jaccard_OT", "Embedding", "sokal_sneath", "sokal_michener",  "rogers_tanimoto", "Hamann", "Cosine"),graph = FALSE)
save(res.mfa.toutes.distances, file = "res.mfa.toutes.distances.RData")
```

## Représentation graphique 

```{r plot_afm, message=FALSE, warning=FALSE}
load("res.mfa.toutes.distances.RData")
# Définir les couleurs dans l'ordre des groupes
custom_colors <- c(
  "forestgreen",  # ACM
  "red",          # Cosine
  "cyan",         # Embedding  
  "black"   ,     # Hamann
  "orange",       # Jaccard
  "grey",         # Jaccard_OT
  "magenta",      # Ochiai
  "green",        # rogers_tanimoto
  "pink",         # sokal_michener
  "skyblue",      # sokal_sneath
  "blue"          # Sorensen
   
)

name.group = c("ACM", "Sorensen", "Ochiai", "Jaccard", "Jaccard_OT", "Embedding", "sokal_sneath", "sokal_michener",  "rogers_tanimoto", "Hamann", "Cosine")


fviz_mfa_var(res.mfa.toutes.distances,
                     choice = 'group',
                     geom = c("point", "text"),
                     repel = TRUE)

fviz_mfa_axes(res.mfa.toutes.distances,
         geom = c('arrow','text'),
         title = "Graphe des axes partiels",
         palette = custom_colors,
         repel = TRUE)
```

# **Assignation de gènes**

## Permutations 

### Définnition des fonctions 

```{r fonction_permut}
# Fonctions vectorisées pour chaque type de distance afin d'effectuer plus rapidement les calculs
calc_distances <- function(matrix1, vector1, method = "sorensen") {
  # Calcul du nombre d'éléments communs (intersections)
  a <- matrix1 %*% vector1
  # Nombre total d'éléments dans chaque ligne de la matrice
  nb_elements_ensemble1 <- rowSums(matrix1)
  b = nb_elements_ensemble1 - a
  # Nombre total d'éléments dans le vecteur
  nb_elements_ensemble2 <- sum(vector1)
  c = nb_elements_ensemble2 - a
  # Calcul du nombre d'éléments présents dans aucun des deux ensembles (d)
  d <- ncol(matrix1) - (a + b + c)
  switch(method,
         "jaccard" = {
           sqrt(1-((a) / (a + b + c)))
         },
         "sokal_michener" = {
           sqrt(1-((a + d )/ (a + b + c+ d)))
         },
         "sokal_sneath" = {
           sqrt(1-((a * d) / (sqrt((a + b) + (a + c)+ (d + b) + (d + c)))))
         },
         "rogers_tanimoto" = {
           sqrt(1-((a + d )/ (a + 2*(b + c)+ d)))
         },
         "sorensen" = {
           sqrt(1-((2*a)/ (2*a + b + c)))
         },
         "hamann" = {
           sqrt(1-((a-(b + c) + d)/(a + b + c+ d)))
         },
         "ochiai" = {
           sqrt(1-((a)/(sqrt(a + b)+(a + c))))
         },
         "cosinus" = {
           1-((a)/(sqrt(a + b)+(a + c)))
         }
  )
}

# Fonction de permutation pour une ligne
permut_all <- function(dta, n_perm, line_idx, distance_method = "sorensen") {
  dta <- as.matrix(dta)
  row <- dta[line_idx, ]
  original_rowname <- rownames(dta)[line_idx]
  pmin <- numeric(n_perm)
  other_rows <- matrix(as.numeric(dta[-line_idx, ]), 
                       nrow = nrow(dta) - 1,
                       byrow = FALSE)
  for(i in 1:n_perm) {
    permuted_row <- sample(row, length(row), replace = FALSE)
    distances <- calc_distances(other_rows, permuted_row, method = distance_method)
    pmin[i] <- min(distances)
  }
  
  return(c(rowname = original_rowname, threshold = min(pmin)))
}

# Fonction pour traiter plusieurs lignes
process_multiple_rows <- function(dta, n_perm, start_idx, end_idx, distance_method = "sorensen") {
  n_rows <- end_idx - start_idx + 1
  results <- matrix(nrow = n_rows, ncol = 2)
  for(i in 1:n_rows) {
    curr_idx <- start_idx + i - 1
    results[i, ] <- permut_all(dta, n_perm, curr_idx, distance_method)
  }
  results_df <- as.data.frame(results)
  colnames(results_df) <- c("rowname", "threshold")
  return(results_df)
}

# Fonction pour exécuter toutes les méthodes de distance
run_all_distances <- function(phenotype_matrix, n_perm = 10, start_idx = 6103, end_idx = 7064) {
  distance_methods <- c("sorensen", "ochiai", "jaccard", "sokal_sneath", 
                        "sokal_michener", "rogers_tanimoto", "hamann", "cosinus")
  results <- list()
  for(method in distance_methods) {
    cat("Processing", method, "distance...\n")
    results[[method]] <- process_multiple_rows(
      phenotype_matrix, 
      n_perm = n_perm, 
      start_idx = start_idx, 
      end_idx = end_idx,
      distance_method = method
    )
    results[[method]]$threshold <- as.numeric(results[[method]]$threshold)
  }
  return(results)
}
```

### Application des permutations 

```{r execute_permut, eval=FALSE}
# Exécuter toutes les distances
results_all <- run_all_distances(phenotype_maladie_s_c)
save(results_all, file="results_all_distances.RData")
```

```{r load_permut}
load ("results_all_distances.RData")
```

### Création des matrices d'assignation 

```{r fonction_matrice_assignation}
# Matrice d'assignation  ----
create_all_association_matrices <- function(results_all) {
  # Liste des matrices de distance à charger
  distance_files <- list(
    sorensen = "dist_or_sorensen_mx.RData",
    ochiai = "dist_or_ochiai_mx.RData",
    jaccard = "dist_or_jaccard_mx.RData",
    sokal_sneath = "dist_or_sokal_sneath_mx.RData",
    sokal_michener = "dist_or_sokal_michener_mx.RData",
    rogers_tanimoto = "dist_or_rogers_tanimoto_mx.RData",
    hamann = "dist_or_hamann_mx.RData",
    cosine = "dist_cosine_mx.RData"
  )
  # Stocker les résultats
  association_matrices <- list()
  # Pour chaque distance
  for(dist_name in names(distance_files)) {
    # Charger la matrice de distance
    load(distance_files[[dist_name]])
    # Obtenir le nom de l'objet chargé
    dist_matrix_name <- gsub("\\.RData$", "", distance_files[[dist_name]])
    dist_matrix <- get(dist_matrix_name)
    # Créer la matrice d'association
    cat("Processing", dist_name, "distance...\n")
    # Conversion en dataframe
    dist_df <- as.data.frame(dist_matrix)
    # Créer une matrice vide
    association_matrix <- matrix(0, nrow = nrow(dist_df), ncol = ncol(dist_df))
    # Pour chaque ligne
    for(i in 1:nrow(dist_df)) {
      # Récupérer le seuil correspondant
      current_threshold <- results_all[[dist_name]]$threshold[i]
      # Comparer les valeurs au seuil
      association_matrix[i,] <- ifelse(dist_df[i,] <= current_threshold, 1, 0)
    }
    # Convertir en dataframe
    association_matrix <- as.data.frame(association_matrix)
    rownames(association_matrix) <- rownames(dist_df)
    colnames(association_matrix) <- colnames(dist_df)
    # Stocker la matrice
    association_matrices[[dist_name]] <- association_matrix
    # Sauvegarder la matrice
    save_name <- paste0("association_matrix_", dist_name, ".RData")
    save(association_matrix, file = save_name)
  }
  return(association_matrices)
}
```

```{r matrice_assignation,eval=FALSE}

# Créer toutes les matrices d'association
association_matrices <- create_all_association_matrices(results_all)
save(association_matrices, file="association_matrices.RData")

```

```{r load_matrice_assign}

load("association_matrices.RData")

```

## Classification 

:::{#intro_classif style="text-align:justify"}

Une autre méthode afin d'obtenir une matrice d'assignation est de passer par une classification. Contrairement aux permutations, la classification peut être utilisée pour l'ensemble des méthodes et non seulement pour les matrices de distances. 

:::

### Préparation des données

```{r prep_classif, eval=FALSE}

row_sorensen = coord_fact_mds_sorensen$conf.row
row_sorensen <- as.data.frame(row_sorensen)
col_sorensen = coord_fact_mds_sorensen$conf.col
col_sorensen <- as.data.frame(col_sorensen)
data_classif_sorensen <- rbind(row_sorensen, col_sorensen)

row_ochiai = coord_fact_mds_ochiai$conf.row
row_ochiai <- as.data.frame(row_ochiai)
col_ochiai = coord_fact_mds_ochiai$conf.col
col_ochiai  <- as.data.frame(col_ochiai )
data_classif_ochiai <- rbind(row_ochiai, col_ochiai)

row_jaccard = coord_fact_mds_jaccard$conf.row
row_jaccard <- as.data.frame(row_jaccard)
col_jaccard = coord_fact_mds_jaccard$conf.col
col_jaccard <- as.data.frame(col_jaccard)
data_classif_jaccard <- rbind(row_jaccard, col_jaccard)

row_ot_jaccard = coord_fact_mds_ot_jaccard$conf.row
row_ot_jaccard <- as.data.frame(row_ot_jaccard)
col_ot_jaccard = coord_fact_mds_ot_jaccard$conf.col
col_ot_jaccard <- as.data.frame(col_ot_jaccard)
data_classif_ot_jaccard <- rbind(row_ot_jaccard, col_ot_jaccard)

data_classif_sokal_sneath <- rbind(coord_fact_mds_sokal_sneath$conf.row, coord_fact_mds_sokal_sneath$conf.col)
data_classif_sokal_michener <- rbind(coord_fact_mds_sokal_michener$conf.row, coord_fact_mds_sokal_michener$conf.col)
data_classif_rogers_tanimoto <- rbind(coord_fact_mds_rogers_tanimoto$conf.row, coord_fact_mds_rogers_tanimoto$conf.col)
data_classif_hamann <- rbind(coord_fact_mds_hamann$conf.row, coord_fact_mds_hamann$conf.col)
data_classif_cosine <- rbind(coord_fact_mds_cosine$conf.row, coord_fact_mds_cosine$conf.col)
data_classif_cosine <- as.data.frame(data_classif_cosine)
data_classif_hamann <- as.data.frame(data_classif_hamann)
data_classif_sokal_michener <- as.data.frame(data_classif_sokal_michener)
data_classif_rogers_tanimoto <- as.data.frame(data_classif_rogers_tanimoto)

data_classif_embedding <- as.data.frame(coord_fact_embedding)
section1 <- data_classif_embedding[1:6102, ]
section2 <- data_classif_embedding[6103:7064, ]
data_classif_embedding <- rbind(section2, section1)
rownames(data_classif_embedding) <- 1:nrow(data_classif_embedding)

data_classif_acm <- as.data.frame(coord_fact_acm)
section1 <- data_classif_acm[1:6102, ]
section2 <- data_classif_acm[6103:7064, ]
data_classif_acm <- rbind(section2, section1)
rownames(data_classif_acm) <- 1:nrow(data_classif_acm)
save(data_classif_acm, file = "data_classif_acm.RData")

names(data_classif_sorensen) <- paste0("D", 1:ncol(data_classif_sorensen))
names(data_classif_ochiai) <- paste0("D", 1:ncol(data_classif_ochiai))
names(data_classif_jaccard) <- paste0("D", 1:ncol(data_classif_jaccard))
names(data_classif_ot_jaccard) <- paste0("D", 1:ncol(data_classif_ot_jaccard))
names(data_classif_embedding) <- paste0("D", 1:ncol(data_classif_embedding))
names(data_classif_acm) <- paste0("D", 1:ncol(data_classif_acm))
names(data_classif_sokal_sneath) <- paste0("D", 1:ncol(data_classif_sokal_sneath))
names(data_classif_sokal_michener) <- paste0("D", 1:ncol(data_classif_sokal_michener))
names(data_classif_rogers_tanimoto) <- paste0("D", 1:ncol(data_classif_rogers_tanimoto))
names(data_classif_hamann) <- paste0("D", 1:ncol(data_classif_hamann))
names(data_classif_cosine) <- paste0("D", 1:ncol(data_classif_cosine))


save(data_classif_sorensen, file="data_classif_sorensen.RData")
save(data_classif_ochiai, file="data_classif_ochiai.RData")
save(data_classif_jaccard, file="data_classif_jaccard.RData")
save(data_classif_ot_jaccard, file="data_classif_ot_jaccard.RData")
save(data_classif_embedding, file="data_classif_embedding.RData")
save(data_classif_acm, file="data_classif_acm.RData")
save(data_classif_sokal_sneath, file="data_classif_sokal_sneath.RData")
save(data_classif_sokal_michener, file="data_classif_sokal_michener.RData")
save(data_classif_rogers_tanimoto, file="data_classif_rogers_tanimoto.RData")
save(data_classif_hamann, file="data_classif_hamann.RData")
save(data_classif_cosine, file="data_classif_cosine.RData")

```

```{r load_data_classif}


load("data_classif_sorensen.RData")
load("data_classif_ochiai.RData")
load("data_classif_jaccard.RData")
load("data_classif_ot_jaccard.RData")
load("data_classif_embedding.RData")
load("data_classif_acm.RData")
load("data_classif_sokal_sneath.RData")
load("data_classif_sokal_michener.RData")
load("data_classif_rogers_tanimoto.RData")
load("data_classif_hamann.RData")
load("data_classif_cosine.RData")


```


### Application de la classification 

:::{#classif style='text-align:justify'}

Nous avons décidé de réaliser une classification à 384 classes, correspondant aux 384 dimensions conservées pour toute les méthodes. Ce choix a été fait car réaliser une classification sur un nombre de classes plus élevés que le nombre de composantes peut s'avérer difficile. 

:::

```{r classif, eval=FALSE}

# Pour sorensen
hc_sorensen <- HCPC(data_classif_sorensen,
                    nb.clust = 384)
save(hc_sorensen, file="hc_sorensen.RData")

# Pour ochiai
hc_ochiai <- HCPC(data_classif_ochiai,
                  nb.clust = 384)
save(hc_ochiai, file="hc_ochiai.RData")

# Pour jaccard
hc_jaccard <- HCPC(data_classif_jaccard,
                   nb.clust = 384)
save(hc_jaccard, file="hc_jaccard.RData")

# Pour ot_jaccard
hc_ot_jaccard <- HCPC(data_classif_ot_jaccard,
                      nb.clust = 384)
save(hc_ot_jaccard, file="hc_ot_jaccard.RData")

# Pour embedding
hc_embedding <- HCPC(data_classif_embedding,
                     nb.clust = 384)
save(hc_embedding, file="hc_embedding.RData")

# Pour acm
hc_acm <- HCPC(data_classif_acm,
               nb.clust = 384)
save(hc_acm, file="hc_acm.RData")

# Pour sokal_sneath
hc_sokal_sneath <- HCPC(data_classif_sokal_sneath,
                        nb.clust = 384)
save(hc_sokal_sneath, file="hc_sokal_sneath.RData")

# Pour sokal_michener
hc_sokal_michener <- HCPC(data_classif_sokal_michener,
                          nb.clust = 384)
save(hc_sokal_michener, file="hc_sokal_michener.RData")

# Pour rogers_tanimoto
hc_rogers_tanimoto <- HCPC(data_classif_rogers_tanimoto,
                           nb.clust = 384)
save(hc_rogers_tanimoto, file="hc_rogers_tanimoto.RData")

# Pour hamann
hc_hamann <- HCPC(data_classif_hamann,
                  nb.clust = 384)
save(hc_hamann, file="hc_hamann.RData")

# Pour cosine
hc_cosine <- HCPC(data_classif_cosine,
                  nb.clust = 384)
save(hc_cosine, file="hc_cosine.RData")

# Création des nouvelles matrices d'assignation à partir du clustering ----

```

```{r load_cluster}

load("hc_sorensen.RData")
load("hc_ochiai.RData")
load("hc_jaccard.RData")
load("hc_ot_jaccard.RData")
load("hc_embedding.RData")
load("hc_acm.RData")
load("hc_sokal_michener.RData")
load("hc_rogers_tanimoto.RData")
load("hc_hamann.RData")
load("hc_cosine.RData")

```

### Transformation 

```{r fonction_transfo_cluster, eval=FALSE}

cluster_sorensen <- hc_sorensen$data.clust
cluster_ochiai <- hc_ochiai$data.clust
cluster_jaccard <- hc_jaccard$data.clust
cluster_ot_jaccard <- hc_ot_jaccard$data.clust
cluster_embedding <- hc_embedding$data.clust
cluster_acm <- hc_acm$data.clust
cluster_sokal_michener <- hc_sokal_michener$data.clust
cluster_rogers_tanimoto <- hc_rogers_tanimoto$data.clust
cluster_hamann <- hc_hamann$data.clust
cluster_cosine <- hc_cosine$data.clust

# Convert clustering results to assignment matrix
create_assignment_matrix <- function(cluster_data) {
  # Extract cluster assignments and row names
  cluster_assignments <- cluster_data[,385]
  all_names <- rownames(cluster_data)
  # Extract names of simple diseases (from index 965 to end)
  ms_names <- all_names[963:length(all_names)]
  mc_names <- all_names[1:962]
  # Create empty matrix
  n_mc <- 962
  n_ms <- 6102
  assignment_matrix <- matrix(0, nrow=n_mc, ncol=n_ms)
  # Fill matrix - 1 if MC and MS are in same cluster
  for(i in 1:n_mc) {
    for(j in 1:n_ms) {
      if(cluster_assignments[i] == cluster_assignments[j+962]) {
        assignment_matrix[i,j] <- 1
      }
    }
  }
  # Add row and column names
  rownames(assignment_matrix) <- mc_names
  colnames(assignment_matrix) <- ms_names
  return(assignment_matrix)
}
```

```{r transfo_cluster,eval=FALSE}

assignment_matrix_sorensen_classif <- create_assignment_matrix(cluster_sorensen)
assignment_matrix_sorensen_classif <- as.data.frame(assignment_matrix_sorensen_classif)
save(assignment_matrix_sorensen_classif, file="assignment_matrix_sorensen_classif.RData")

assignment_matrix_ochiai_classif <- create_assignment_matrix(cluster_ochiai)
assignment_matrix_ochiai_classif <- as.data.frame(assignment_matrix_ochiai_classif)
save(assignment_matrix_ochiai_classif, file="assignment_matrix_ochiai_classif.RData")

assignment_matrix_jaccard_classif <- create_assignment_matrix(cluster_jaccard)
assignment_matrix_jaccard_classif <- as.data.frame(assignment_matrix_jaccard_classif)
save(assignment_matrix_jaccard_classif, file="assignment_matrix_jaccard_classif.RData")

assignment_matrix_ot_jaccard_classif <- create_assignment_matrix(cluster_ot_jaccard)
assignment_matrix_ot_jaccard_classif <- as.data.frame(assignment_matrix_ot_jaccard_classif)
save(assignment_matrix_ot_jaccard_classif, file="assignment_matrix_ot_jaccard_classif.RData")

assignment_matrix_embedding_classif <- create_assignment_matrix(cluster_embedding)
assignment_matrix_embedding_classif <- as.data.frame(assignment_matrix_embedding_classif)
save(assignment_matrix_embedding_classif, file="assignment_matrix_embedding_classif.RData")

assignment_matrix_acm_classif <- create_assignment_matrix(cluster_acm)
assignment_matrix_acm_classif <- as.data.frame(assignment_matrix_acm_classif)
save(assignment_matrix_acm_classif, file="assignment_matrix_acm_classif.RData")

assignment_matrix_sokal_michener_classif <- create_assignment_matrix(cluster_sokal_michener)
assignment_matrix_sokal_michener_classif <- as.data.frame(assignment_matrix_sokal_michener_classif)
save(assignment_matrix_sokal_michener_classif, file="assignment_matrix_sokal_michener_classif.RData")

assignment_matrix_rogers_tanimoto_classif <- create_assignment_matrix(cluster_rogers_tanimoto)
assignment_matrix_rogers_tanimoto_classif <- as.data.frame(assignment_matrix_rogers_tanimoto_classif)
save(assignment_matrix_rogers_tanimoto_classif, file="assignment_matrix_rogers_tanimoto_classif.RData")

assignment_matrix_hamann_classif <- create_assignment_matrix(cluster_hamann)
assignment_matrix_hamann_classif <- as.data.frame(assignment_matrix_hamann_classif)
save(assignment_matrix_hamann_classif, file="assignment_matrix_hamann_classif.RData")

assignment_matrix_cosine_classif <- create_assignment_matrix(cluster_cosine)
assignment_matrix_cosine_classif <- as.data.frame(assignment_matrix_cosine_classif)
save(assignment_matrix_cosine_classif, file="assignment_matrix_cosine_classif.RData")

```

```{r load_transfo_cluster}

load("assignment_matrix_sorensen_classif.RData")
# load("assignment_matrix_ochiai_classif.RData")
load("assignment_matrix_jaccard_classif.RData")
load("assignment_matrix_ot_jaccard_classif.RData")
load("assignment_matrix_embedding_classif.RData")
load("assignment_matrix_acm_classif.RData")
load("assignment_matrix_sokal_michener_classif.RData")
load("assignment_matrix_rogers_tanimoto_classif.RData")
load("assignment_matrix_hamann_classif.RData")
load("assignment_matrix_cosine_classif.RData")

rownames(assignment_matrix_sorensen_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
colnames(assignment_matrix_sorensen_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

# rownames(assignment_matrix_ochiai_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
# colnames(assignment_matrix_ochiai_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

rownames(assignment_matrix_jaccard_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
colnames(assignment_matrix_jaccard_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

rownames(assignment_matrix_ot_jaccard_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
colnames(assignment_matrix_ot_jaccard_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

rownames(assignment_matrix_embedding_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
colnames(assignment_matrix_embedding_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

rownames(assignment_matrix_acm_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
colnames(assignment_matrix_acm_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

rownames(assignment_matrix_sokal_michener_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
colnames(assignment_matrix_sokal_michener_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

rownames(assignment_matrix_rogers_tanimoto_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
colnames(assignment_matrix_rogers_tanimoto_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

rownames(assignment_matrix_hamann_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
colnames(assignment_matrix_hamann_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

rownames(assignment_matrix_cosine_classif) <- rownames(phenotype_maladie_s_c[6103:7064,])
colnames(assignment_matrix_cosine_classif) <- rownames(phenotype_maladie_s_c[1:6102,])

```




