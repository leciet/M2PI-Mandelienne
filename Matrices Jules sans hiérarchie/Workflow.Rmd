---
title: "Workflow"
author: 
  - Leslie CIETERS^[leslie.cieters@agrocampus-ouest.fr]
  - Nemo DIDIER^[nemo.didier@agrocampus-ouest.fr]
  - Sara LARCHER^[sara.larcher@agrocampus-ouest.fr]
date: "2025-01-15"
output: 
  html_document:
    toc: true
    number_sections: true
    theme: flatly
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

------------------------------------------------------------------------

::: {#introduction style="text-align: justify;"}
Les maladies simples sont **monogéniques**, issues de mutations localisées sur les exons, et bien étudiées. Elles déclenchent des phénotypes précis, permettant d'identifier facilement le lien entre un phénotype et le gène impliqué. En revanche, les maladies complexes, **multigéniques**, peuvent impacter d'autres régions moins bien connues que les exons et plusieurs régions à la fois. Il est donc difficile, à partir des phénotypes, de déterminer les gènes impliqués.

L'**objectif** de ce document est de proposer, pour chaque maladie complexe, une liste des gènes impliqués. Pour cela, nous exploitons les maladies simples proches d'une maladie complexe donnée pour identifier des phénotypes communs, permettant de définir une liste de gènes potentiellement responsables de la maladie complexe afin d'orienter la recherche. **Les associations gène-maladie ne sont pas interprétées à ce stade**.

*Cette démarche s'inscrit dans une volonté d'aide à la recherche médicale et ne doit pas être utilisée telle quelle.*
:::

## Démarche

::: {style="test-align: justify"}
Le projet s’articule autour de deux étapes principales :

1.  **Calcul d’une matrice de distance et des coordonnées dans un nombre de dimensions finis** : Il s'agit de projeter des maladies simples et complexes dans un espace commun.

2.  **Définition d’un seuil d’assignation des gènes** : On utilise un seuil global ou spécifique à chaque maladie complexe, au travers de plusieurs méthodes.

À chacune des étapes nous cherchons à comparer plusieurs méthodes pour obtenir la plus adaptée à notre contexte.
:::

## Packages requis

::: {style="text-align: justify"}
Les packages suivants sont utilisés dans ce workflow
:::

```{r import_packages, message=FALSE, warning=FALSE}

require(tidyverse)
require(FactoMineR)
require(ade4)
require(vegan)
require(reshape)
require(DataExplorer)
require(smacof)
require(Matrix)
require(proxy)
require(pheatmap)
if (!require("ontologyIndex")) install.packages("ontologyIndex", repos = "http://cran.us.r-project.org")
library(ontologyIndex)
library(knitr)
```

# Préparation des données

------------------------------------------------------------------------

Les données initiales sont isssues de deux bases de données différentes :

-   `OMIM` pour les maladies simples

-   `Phecode` pour les maladies complexes

Il s'agit de tableau de Présence/Absence où chaque ligne représente une maladie et chaque colonne un phénotype

|           | Phénotype 1 | Phénotype 2 |
|:---------:|:-----------:|:-----------:|
| Maladie 1 |      0      |      1      |
| Maladie 2 |      1      |      1      |
| Maladie 3 |      1      |      0      |

: **Structure des données**

::: {style="text-align:justify"}
Les phénotypes peuvent différer d'une base à une autre. Afin de comparer maladies simples et complexes, on ne récupère que les phénotypes communs aux deux bases de données. De plus on retire du jeu de données final, toutes les maladies ne présentant pas de variabilité dans les phénotypes observés (c'est-à-dire ne présentant que des absences pour l'ensemble des phénotypes étudiés).
:::

## Prétraitement

```{r pretraitement_data,eval=FALSE}

# Importation des données 
Phe_OMIM <- read.csv('Profils_Base_OMIM.csv')
Phe_Phecode <- read.csv('Profils_Base_Phecodes.csv')

# Passage des noms de maladies en noms de lignes
rownames(Phe_OMIM) <- Phe_OMIM[,1]
rownames(Phe_Phecode) <- Phe_Phecode[,1]
Phe_OMIM <- Phe_OMIM[,-1]
Phe_Phecode <- Phe_Phecode[,-1]

# Intersection des ensembles de phénotypes des deux bases de données
colonnes_communes <- intersect(colnames(Phe_OMIM), colnames(Phe_Phecode))
Phe_OMIM_communes <- Phe_OMIM[, colonnes_communes, drop = FALSE]
Phe_Phecode_communes <- Phe_Phecode[, colonnes_communes, drop = FALSE]

# Fusion des jeux de données 
mc_ms_communes <- rbind(Phe_OMIM_communes, Phe_Phecode_communes)

# Filtre des maladies sans variabilité 
mc_ms_communes_filtre_row <- mc_ms_communes %>%
  filter(rowSums(mc_ms_communes)!=0)
mc_ms_communes_filtre_col_row <- mc_ms_communes_filtre_row %>%
  select(where(~sum(.) != 0))
mc_ms_communes_filtre_col_row <- mc_ms_communes_filtre_row[, colSums(mc_ms_communes_filtre_row) != 0]

phenotype_maladie_s_c <- mc_ms_communes_filtre_col_row
phenotype_maladie_s_c <-  as.data.frame(phenotype_maladie_s_c)

# Sauvegarde du jeu de données prétraité
save(phenotype_maladie_s_c, file="phenotype_maladie_s_c.RData")
```

## Chargement

```{r load_data}

# Chargement du jeu de données sauvegardé 
load('phenotype_maladie_s_c.RData')

# Fichiers HPO pour obtenir le nom des phénotypes 
hpo_url <- "https://raw.githubusercontent.com/obophenotype/human-phenotype-ontology/master/hp.obo"
hpo <- get_ontology(hpo_url, extract_tags = 'everything')

name_ph <- hpo$name
formatted_colnames <- gsub("\\.", ":", colnames(phenotype_maladie_s_c))

# Changement des codes phénotypes par leur nom complet
colnames(phenotype_maladie_s_c) <- name_ph[formatted_colnames]

```

## Structure des données

```{r vizu_data}

# Fonction utilitaire pour calculer le pourcentage de valeurs non-nulles
sparsity_stats <- function(matrix) {
  n_nonzero <- sum(matrix != 0)
  total <- prod(dim(matrix))
  return(list(
    densité = n_nonzero/total * 100,
    nb_nonzero = n_nonzero
  ))
}

## Statistiques descriptives

# Séparation des maladies simples et complexes
maladies_simples <- phenotype_maladie_s_c[1:6102,]
maladies_complexes <- phenotype_maladie_s_c[6103:7064,]

# Calcul des statistiques
stats_total <- sparsity_stats(phenotype_maladie_s_c)
stats_simples <- sparsity_stats(maladies_simples)
stats_complexes <- sparsity_stats(maladies_complexes)

# Affichage des résultats
cat(sprintf("Statistiques de densité de la matrice:\n  - Totale: %.2f%%\n  - Maladies simples: %.2f%%\n  - Maladies complexes: %.2f%%",
            stats_total$densité,
            stats_simples$densité,
            stats_complexes$densité))

```

::: {style="test-align:justify"}
On observe que la matrice initiale est creuse. Cela est à prendre en compte dans la suite de l'analyse.
:::

```{r boxplot_data}
## Distribution des associations par type de maladie
# Calcul du nombre de phénotypes par maladie
phenotypes_par_maladie <- rowSums(phenotype_maladie_s_c != 0)

# Création d'un dataframe pour ggplot
df_dist <- data.frame(
  nb_phenotypes = phenotypes_par_maladie,
  type = c(rep("Simple", 6102), rep("Complexe", 962))
)

# Visualisation avec des boxplots
ggplot(df_dist, aes(x = type, y = nb_phenotypes, fill = type)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribution du nombre de phénotypes par type de maladie",
       x = "Type de maladie",
       y = "Nombre de phénotypes associés")+
  theme(legend.position = 'none')
```

```{r phenotypes_data}
## Analyse des phénotypes les plus fréquents
# Calcul des fréquences des phénotypes
phenotype_freq <- colSums(phenotype_maladie_s_c != 0)
top_n <- 20

# Création d'un dataframe pour les top phénotypes
top_phenotypes <- data.frame(
  phenotype = names(sort(phenotype_freq, decreasing = TRUE)[1:top_n]),
  frequency = sort(phenotype_freq, decreasing = TRUE)[1:top_n]
)

# Visualisation
ggplot(top_phenotypes, aes(x = reorder(phenotype, frequency), y = frequency)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Phénotypes les plus fréquents",
       x = "Phénotype",
       y = "Nombre de maladies associées")
```

# Calcul de matrices de distances 

--------------------------------------------------------------------------------
::: {style="test-align: justify"}
Ici on cherche à caluler des distances binaires, c'est-à-dire des distances sur une matrice binaire avec **1=Présence** et **0=Absence**. <br>
On note : 
:::
- $n_{11} = a$ nombre de phénotypes présents dans les deux maladies
- $n_{10} = b$ nombre de phénotypes présents uniquement dans la première maladie
- $n_{01} = c$ nombre de phénotypes présents uniquement dans la deuxième maladie
- $n_{00} = d$ nombre de phénotypes absents dans les deux maladies

## Calcul des distances {.tabset}

### Jaccard {.unnumbered}

$$d_{Jaccard}=\sqrt{1-\frac{a}{a+b+c}}$$

```{r jaccard, eval=FALSE}

index_ASCVD <- which(rownames(phenotype_maladie_s_c) == "ASCVD")
rownames(phenotype_maladie_s_c[6103,])
rownames(phenotype_maladie_s_c[6102,])

dist_or_jaccard <- dist.binary(phenotype_maladie_s_c, method = 1)
dist_or_jaccard <- as.data.frame(as.matrix(dist_or_jaccard))
dist_or_jaccard <- dist_or_jaccard[6103:7064, 1:6102]  # Extraction du sous-ensemble MC-MS
dist_or_jaccard_mx <- as.matrix(dist_or_jaccard)

save(dist_or_jaccard_mx, file="dist_or_jaccard_mx.RData")

```

### SMC {.unnumbered}

$$d_{SMC}=\sqrt{1-\frac{a+d}{a+b+c+d}}$$

```{r smc, eval=FALSE}

dist_or_smc <- dist.binary(phenotype_maladie_s_c, method = 2)
dist_or_smc <- as.data.frame(as.matrix(dist_or_smc))
dist_or_smc <- dist_or_smc[6103:7064, 1:6102]
dist_or_smc_mx <- as.matrix(dist_or_smc)

save(dist_or_smc_mx, file="dist_or_smc_mx.RData")

```

### Sokal et sneath {.unnumbered}
$$d_{Sokal-Sneath}=\sqrt{1-\frac{a}{a+2(b+c)}}$$

```{r sokal-sneath, eval=FALSE}

dist_or_sokal_sneath <- dist.binary(phenotype_maladie_s_c, method = 3) 
dist_or_sokal_sneath <- as.data.frame(as.matrix(dist_or_sokal_sneath))
dist_or_sokal_sneath <- dist_or_sokal_sneath[6103:7064, 1:6102]
dist_or_sokal_sneath_mx <- as.matrix(dist_or_sokal_sneath)

save(dist_or_sokal_sneath_mx, file="dist_or_sokal_sneath_mx.RData")

```

### Rogers et Tanimoto {.unnumbered}

$$d_{Rogers-Tanimoto}=\sqrt{1-\frac{a+d}{a+2(b+c)+d}}$$

```{r rogers-tanimoto, eval=FALSE}

dist_or_rogers_tanimoto  <- dist.binary(phenotype_maladie_s_c, method = 4)
dist_or_rogers_tanimoto <- as.data.frame(as.matrix(dist_or_rogers_tanimoto))
dist_or_rogers_tanimoto <- dist_or_rogers_tanimoto[6103:7064, 1:6102]
dist_or_rogers_tanimoto_mx <- as.matrix(dist_or_rogers_tanimoto)

save(dist_or_rogers_tanimoto_mx, file="dist_or_rogers_tanimoto_mx.RData")

```

### Sorensen {.unnumbered}

$$d_{Sorensen}=\sqrt{1-\frac{2a}{2a+b+c}}$$

```{r sorensen, eval=FALSE}

dist_or_sorensen <- dist.binary(phenotype_maladie_s_c, method = 5)
dist_or_sorensen <- as.data.frame(as.matrix(dist_or_sorensen))
dist_or_sorensen <- dist_or_sorensen[6103:7064, 1:6102]
dist_or_sorensen_mx <- as.matrix(dist_or_sorensen)

save(dist_or_sorensen_mx, file="dist_or_sorensen_mx.RData")

```

### Hamann {.unnumbered}

$$d_{Hamann}=\sqrt{1-\frac{a-(b+c)+d}{a+b+c+d}}$$

```{r hamann,eval=FALSE}

dist_or_hamann <- dist.binary(phenotype_maladie_s_c, method = 6) 
dist_or_hamann <- as.data.frame(as.matrix(dist_or_hamann))
dist_or_hamann <- dist_or_hamann[6103:7064, 1:6102]
dist_or_hamann_mx <- as.matrix(dist_or_hamann)

save(dist_or_hamann_mx, file="dist_or_hamann_mx.RData")

```

### Ochiai {.unnumbered}

$$d_{Ochiai}=\sqrt{1-\frac{a}{\sqrt{(a+b)(a+c)}}}$$

```{r ochiai, eval=FALSE}

dist_or_ochiai <- dist.binary(phenotype_maladie_s_c, method = 7)
dist_or_ochiai <- as.data.frame(as.matrix(dist_or_ochiai))
dist_or_ochiai <- dist_or_ochiai[6103:7064, 1:6102]
dist_or_ochiai_mx <- as.matrix(dist_or_ochiai)

save(dist_or_ochiai_mx, file="dist_or_ochiai_mx.RData")

```

### Cosine {.unnumbered}

$$d_{Cosine} = 1 - \frac{a}{\sqrt{(a + b)(a + c)}}$$

```{r cosine,eval=FALSE}

dist_cosine <- dist(phenotype_maladie_s_c, method = "cosine")
dist_cosine <- as.data.frame(as.matrix(dist_cosine))
dist_cosine <- dist_cosine[6103:7064, 1:6102]
dist_cosine_mx <- as.matrix(dist_cosine)

save(dist_cosine_mx, file="dist_cosine_mx.RData")
```

## Comparaison des méthodes
```{r table_comp, echo=FALSE}

# Créer un tableau avec des données
tableau <- data.frame(
  Méthode = c("Jaccard", "SMC", "Sokal et Sneath", "Rogers et Tanimoto", "Sorensen", "Hamann", "Ochiai", "Cosine"),
  Description = c("Calcule la similarité en fonction de la proportion d'éléments communs.",
                  "Calcule la proportion de concordances parmi tous les éléments.",
                  "Variation de la distance de Jaccard qui prend en compte les concordances des absences.",
                  "Mesure la similarité en prenant en compte les présences et les absences.",
                  "Similaire au Jaccard mais avec un facteur multiplicatif pour augmenter la pondération des présences communes.",
                  "Mesure qui prend en compte à la fois la présence et l’absence en équilibrant les deux.",
                  "Mesure la similarité en fonction du rapport entre la taille des ensembles et des éléments communs.",
                  "Compare deux ensembles comme des vecteurs dans un espace multidimensionnel."),
  Pertinence = c("Bien adapté pour des données où l'absence est fréquente et où seules les présences sont d'intérêt.",
                 "Convient pour des ensembles où la présence et l'absence sont toutes deux significatives.",
                 "Pertinente pour des données binaires où les absences sont aussi importantes que les présences.",
                 "Adaptée lorsque les absences sont importantes et qu’on veut différencier les éléments présents et absents.",
                 "Utilisée lorsqu’on souhaite plus de poids pour les éléments présents, ce qui est pertinent dans certains jeux de données.",
                 "Utile pour des données où l’absence et la présence sont toutes deux importantes et où l’équilibre est nécessaire.",
                 "Adaptée aux données binaires où l’on veut une mesure de similarité robuste, même pour les ensembles de taille inégale.",
                 "Très adaptée aux données creuses où les ensembles peuvent être représentés comme des vecteurs binaires."),
  Avantages = c("Simple à calculer et interpréter. Bien adapté pour les données creuses.",
                "Prend en compte les absences et les présences.",
                "Bien équilibré entre présence et absence.",
                "Permet une comparaison nuancée, plus détaillée que le Jaccard.",
                "Facile à calculer, adaptée pour les données avec une dominance de présence.",
                "Robuste et équilibrée entre présence et absence.",
                "Bien adaptée aux données binaires déséquilibrées, calcul rapide.",
                "Prend bien en compte la direction des vecteurs, souvent utilisé dans des contextes avec des données creuses."),
  Inconvénients = c("Ne prend pas en compte les absences simultanées.",
                   "Peut accorder trop de poids aux absences, ce qui n'est pas toujours pertinent.",
                   "Plus complexe à interpréter que le Jaccard.",
                   "Moins robuste si les absences sont trop fréquentes.",
                   "Ne prend pas bien en compte les absences, moins efficace pour des données très creuses.",
                   "Plus difficile à interpréter et peut être moins intuitive dans des jeux de données simples.",
                   "Moins efficace avec des ensembles ayant de nombreuses absences simultanées.",
                   "Peut ne pas être adaptée aux ensembles avec des distributions très inégales des présences et absences.")
)

# Afficher le tableau avec kable pour HTML
kable(tableau, caption = "Comparaison des méthodes de distance", format = "html", table.attr = "class='table table-bordered'")
```
