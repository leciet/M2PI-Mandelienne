---
title: "Work flow"
author: "Sara Larcher"
date: "2024-12-03"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

Téléchargement de la data-base propre. Les actions effectuées dessus
sont les suivantes:

-   Association des deux tableaux MS et MC en lignes et phénotypes en
    colonnes

-   Suppression des maladies n'ayant aucun phenotype observe

-   Vérification de la variabilité par colonnes sur les tableaux simples
    (MS/MC) et sur le tableau total

Le jeu de données utilisé est new_full.\
Ce jeu de données supprime deux maladies complexes n'ayant pas de
variabilité dans leurs phénotypes (0 pour l'ensemble des phénotypes)

```{r setup, include=FALSE}
library(FactoMineR)
library(factoextra)
library(ade4) 
library(tidyverse)
library(reshape)

load("data_clean.RData")
```

## Etape 1 : Application et obtention des matrices de distances

#### a) A partir d'une ACM

Nous suivons la convention suivant
*`origine des données_type de distance_type d'objet.`* Les objets sont
stockés dans le dossier "Objets R" et peuvent être load directement.

```{r cars}
mandale <- readRDS("~/R/M2PI-Mendelienne/Visualisation factorielle/mandale.rds")

actif <- mandale$ind$coord
sup <- mandale$ind.sup$coord
dta_dist <- rbind(actif, sup)


dist_acm_eucli <- get_dist(dta_dist, method = "euclidean")
dist_acm_eucli <- as.data.frame(as.matrix(dist_acm_eucli))
dist_acm_eucli_mx <-as.matrix(dist_acm_eucli[6126:7089, 1:6125])

dist_acm_manhattan<- get_dist(dta_dist, method = "manhattan")
dist_acm_manhattan <- as.data.frame(as.matrix(dist_acm_manhattan))
dist_acm_manhattan_mx <- as.matrix(dist_acm_manhattan[6126:7089, 1:6125])

```

#### b) A partir de la matrice d'origine

```{r}

or_filter_df0 <- or_df0 %>% 
  filter(rowSums(or_df0)!=0)

dist_or_sorensen <- dist.binary(or_filter_df0 ,method = 5) #Long 
dist_or_sorensen <- as.data.frame(as.matrix(dist_or_sorensen))
dist_or_sorensen <- dist_or_sorensen[6126:7089,1:6125]
dist_or_sorensen_mx<- as.matrix(dist_or_sorensen)

dist_or_ochiai<- dist.binary(new_full,method = 7)
dist_or_ochiai <- as.data.frame(as.matrix(dist_or_ochiai))
dist_or_ochiai  <- dist_or_ochiai[6126:7089,1:6125]
dist_or_ochiai_mx  <- as.matrix(dist_or_ochiai)
```

## Etape 2 : Standardisation des matrices de distance et obtention d'une matrice de distance consensus

Obtention de la matrice consensus

```{r}
max(dist_acm_eucli_mx)
max(dist_acm_manhattan_mx)
max(dist_or_ochiai_mx)
max(dist_or_sorensen_mx)

min(dist_acm_eucli_mx)
min(dist_acm_manhattan_mx)
min(dist_or_ochiai_mx)
min(dist_or_sorensen_mx)

# Fonction de normalisation Min-Max
min_max_normalize <- function(matrix) {
  (matrix - min(matrix)) / (max(matrix) - min(matrix))
}

# Appliquer Min-Max aux matrices
dist_acm_eucli_minmax <- min_max_normalize(dist_acm_eucli_mx)
dist_acm_manhattan_minmax <- min_max_normalize(dist_acm_manhattan_mx)

# Vérification des plages pour Ochiai et Sorensen
range(dist_or_ochiai_mx)   # Doit être [0, 1]
range(dist_or_sorensen_mx) # Doit être [0, 1]
range(dist_acm_eucli_minmax)
range(dist_acm_manhattan_minmax)

```

Obtention de la matrice consensus

```{r}
matrices <- list(dist_acm_eucli_minmax, dist_acm_manhattan_minmax, dist_or_ochiai_mx,dist_or_sorensen_mx)

#Test poids egaux 
poids <- c(0.25, 0.25, 0.25,0.25)
#Test poids avec variance (diversite transcrit dans les distances)
variances <- sapply(matrices, function(mat) var(as.vector(mat)))
poids <- 1 / variances
poids <- poids / sum(poids)

dist_consensus <- Reduce(`+`, Map(`*`, matrices, poids))
str(dist_consensus)
```

Etape 2 bis : Comparaison des matrices entre elles

```{r}
#Code Nemo 
```

## Etape 3 : Obtention d'une matrice "robuste" d'assignation

Détermination de l'existence d'une association entre gènes et maladies
complexes Méthode p-value empirique : n'a pas besoin que la distribution
de nos maladies complexes soient normales

```{r}
compute_empirical_pvalues <- function(row) {
  sapply(row, function(d) {
    sum(row <= d) / length(row)  # Proportion de distances <= d
  })
}

# Calculer les p-values empiriques pour chaque ligne
empirical_pvalues <- t(apply(dist_consensus, 1, compute_empirical_pvalues))
View(empirical_pvalues)

# Sélection des gènes avec un seuil de p-value
alpha <- 0.01
selected_genes <- data.frame(ifelse(empirical_pvalues<=alpha,1,0))

selected_genes <- as.matrix(selected_genes) 
View(selected_genes)
View(rowSums(selected_genes))

heatmap(
  selected_genes,
  col = c("white", "black"),
  scale = "none",
  Rowv = NA,
  Colv = NA,
  main = "P-value empirique"
)


#Ou fonction avec les seuils à faire 
```

```{r}
compute_empirical_pvalues <- function(row) {
  sapply(row, function(d) {
    sum(row <= d) / length(row)  # Proportion de distances <= d
  })
}

set.seed(42)  
n_bootstrap <- 1000
# Matrice pour stocker les p-values bootstrap
bootstrap_pvalues <- array(NA, dim = c(nrow(dist_consensus), ncol(dist_consensus), n_bootstrap))
for (b in 1:n_bootstrap) {
  # Échantillon bootstrap (avec remise)
  bootstrap_sample <- dist_consensus[sample(1:nrow(dist_consensus), replace = TRUE), ]
  # Calcul des p-values empiriques pour l'échantillon bootstrap
  for (i in 1:nrow(bootstrap_sample)) {
    bootstrap_pvalues[i, , b] <- compute_empirical_pvalues(bootstrap_sample[i, ])
  }
}
# Calcul de la p-value moyenne pour chaque maladie et chaque gène
mean_pvalues <- apply(bootstrap_pvalues, c(1, 2), mean)
# Calcul de l'écart-type des p-values (pour évaluer la variabilité)
std_pvalues <- apply(bootstrap_pvalues, c(1, 2), sd)

# Exemple : Filtrer les gènes significatifs pour une maladie donnée
significant_genes <- which(mean_pvalues[1, ] <= 0.05)  # Gènes avec p-value moyenne <= 0.05



```

## Etape 4 : Etablissement du couplage MC x liste(gènes)

```{r}
#Modifier pour utiliser le vecteur des seuils calculé avant 

#' AssignGene
#' @description
#' Assigne une liste de gènes à chaque maladie complexe, la matrice de distances a en colonne les ms et en ligne les mc
#'
#' @param dist objet  matrix correspondant à la matrice de distances
#' @param method 'seuil' ou 'quantile' pour le critère d'association
#' @param s paramètre pour la méthode seuil
#' @param q paramètre pour la méthode quantile
#' @param graph si TRUE affiche la matrice d'association
#'
#' @return une liste contenant 2 objets correspondant à l'assignation d'une liste de gènes par maladie et la matrice d'assignation
#' @export
#'
#' @examples
AssignGene <- function(dist, method='seuil' , s = 0.5 , q = 0.25 , graph = TRUE){
  # Conversion de la matrice en format long
  flong <- melt(dist)
  colnames(flong) <- c("mc", "ms", "distance")
  
  if(method=='seuil'){
    if (s<0 | s>1) {
      stop("Le seuil doit être compris entre 0 et 1")
    }
    flong_filtre <- flong %>% 
      filter(distance<=s) %>% 
      group_by(mc) %>% 
      summarise( mc = mc, ms=ms, distance=distance, liste_genes = paste(ms,collapse = " ; "),.groups = 'drop')
  } else if(method=='quantile'){
    if (q<0 | q>1) {
      stop("Le quantile doit être compris entre 0 et 1")
    }
    flong_filtre <- flong %>% 
      filter(distance<=quantile(distance,q))%>% 
      group_by(mc) %>% 
      summarise( mc = mc, ms=ms, distance=distance, liste_genes = paste(ms,collapse = " ; "),.groups = 'drop')
  } else{
    stop('méthode non reconnue')
  }
  assign_liste <- unique(flong_filtre[,c(1,4)])
  assign_matrice <-  flong_filtre[,1:3] %>% 
    mutate(distance=ifelse(distance!=0,1,0)) %>% 
    pivot_wider(names_from = ms,values_from = distance) 
  
  if(graph==TRUE){
    plot <- flong_filtre %>% 
      mutate(distance=ifelse(distance!=0,1,0)) %>% 
      ggplot( aes(x = ms, y = mc, fill = distance)) +
        geom_tile() +
        scale_fill_gradient(low = "pink2", high = "firebrick") +
        labs(title = "Matrice d'Association", x = "MS", y = "MC", fill = "Distance")+
        theme(axis.text.x = element_text(angle = 30,size = 2),
            axis.text.y = element_text(size=3))
    print(plot)
  }
  
  return(list(assign_liste,assign_matrice))
  
}

```

1ère méthode : méthode classique d'assignation avec seuil ou quantile

```{r}
#Obtention de la matrice avec des "pourcentage de croyance" dans l'association 
#Choix d'un seuil de confiance =
#Obtention liste de gène 
#

res.list <- AssignGene(dist_consensus, method = "seuil", 0.7)
View(res.list[[1]])

```

Analyse en cours de test des poids

```{r}
 -->

<!-- ```{r} -->

<!-- dist_consensus <- function(poids, matrices) { -->

<!--   Reduce(`+`, Map(`*`, matrices, poids)) -->

<!-- } -->

<!-- evaluate_consensus <- function(dist_consensus, reference) { -->

<!--   sum((dist_consensus - reference)^2) -->

<!-- } -->

<!-- # Générer des combinaisons de poids -->

<!-- grid_size <- 10   -->

<!-- poids_grid <- expand.grid(seq(0, 1, length.out = grid_size), -->

<!--                             seq(0, 1, length.out = grid_size)) -->

<!-- # Filtrer les combinaisons où la somme des poids est proche de 1 -->

<!-- poids_grid <- weights_grid[rowSums(poids_grid) <= 1, ] -->

<!-- poids_grid <- cbind(poids_grid, 1 - rowSums(poids_grid)) -->

<!-- colnames(wpoids_grid) <- paste0("w", 1:3) -->

<!-- # Matrice de référence (par exemple, moyenne des matrices) -->

<!-- reference <- Reduce(`+`, matrices) / length(matrices) -->

<!-- # Analyse des résultats -->

<!-- results <- apply(weights_grid, 1, function(poids) { -->

<!--   consensus <- compute_consensus(poids, matrices) -->

<!--   metric <- evaluate_consensus(dist_consensus, reference) -->

<!--   metric -->

<!-- }) -->

<!-- # Ajouter les résultats aux poids -->

<!-- sensitivity_results <- cbind(poids_grid, metric = results) -->

<!-- # Visualiser les résultats -->

<!-- library(ggplot2) -->

<!-- ggplot(as.data.frame(sensitivity_results), aes(x = w1, y = w2, z = metric)) + -->

<!--   geom_contour_filled() + -->

<!--   labs(title = "Analyse de sensibilité des poids", -->

<!--        x = "Poids pour Mat1", y = "Poids pour Mat2", fill = "Métrique") + -->

<!--   theme_minimal() -->

<!-- ``` -->

<!-- Mise en place d'échantillonnage plus petit (pas bon en cours) -->

<!-- ```{r}  -->

<!-- filtre_col <- function(data, num_colonnes) { -->

<!--   colonnes_selectionnees <- sample(colnames(data), num_colonnes) -->

<!--   data_selectionnee <- data[, colonnes_selectionnees, drop = FALSE] -->

<!--   result <- data[apply(data, 1, function(ligne) {  -->

<!--     colonnes_avec_1 <- names(ligne)[ligne == 1] -->

<!--     return(all(colonnes_avec_1 %in% colnames(data_selectionnee))) -->

<!--   }), colonnes_selectionnees, drop = FALSE] -->

<!--   return(result) -->

<!-- } -->

<!-- dta_small_col <- filtre_col(new_full, 100) -->

<!-- # Traitement sur phecode -->

<!-- rownames(phecode) <- phecode[[1]] -->

<!-- phecode <- phecode[-1] -->

<!-- filtre_ligne <- function(data_mc, data, num_lignes) { -->

<!--   lignes_selectionnees <- sample(1:nrow(data_mc), num_lignes) -->

<!--   lignes_noms <- rownames(data_mc)[lignes_selectionnees] -->

<!--   colonnes_avec_1 <- colnames(data)[apply(data[lignes_noms, ], 2, function(colonne) { -->

<!--     return(any(colonne == 1)) -->

<!--   })] -->

<!--   result <- data[apply(data, 1, function(ligne) { -->

<!--     colonnes_avec_1_ligne <- names(ligne)[ligne == 1] -->

<!--     return(all(colonnes_avec_1_ligne %in% colonnes_avec_1)) -->

<!--   }), colnames(data) %in% colonnes_avec_1, drop = FALSE] -->

<!--   return(result) -->

<!-- } -->

<!-- dta_small_row <- filtre_ligne(phecode, new_full, 10) -->

<!-- ``` -->
```
